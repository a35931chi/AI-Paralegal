{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "path_to_model = r'C:\\Users\\inves\\AppData\\Local\\Programs\\Python\\Python35\\Lib\\site-packages\\nltk\\stanford-ner-2018-02-27\\classifiers\\english.all.3class.distsim.crf.ser.gz'\n",
    "path_to_jar = r'C:\\Users\\inves\\AppData\\Local\\Programs\\Python\\Python35\\Lib\\site-packages\\nltk\\stanford-ner-2018-02-27\\stanford-ner.jar'\n",
    "tagger = StanfordNERTagger(path_to_model, path_to_jar = path_to_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "#visualization libraries\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import itertools as it\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import re\n",
    "import datetime\n",
    "import string\n",
    "import time\n",
    "\n",
    "java_path = 'C:/Program Files/Java/jdk-10.0.1/bin/java.exe'\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\inves\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\inves\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\inves\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docket_original = list(new_df['Original Docket Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(5):\n",
    "    org_str = []\n",
    "    name_str = []\n",
    "    stripped_str1 = []\n",
    "    stripped_str2 = []\n",
    "\n",
    "    tokens = word_tokenize(docket_original[i])\n",
    "    for SFlabel, NLlabel, token in zip(tagger.tag(tokens), tree2conlltags(ne_chunk(pos_tag(tokens))), tokens):\n",
    "        print(SFlabel, NLlabel, token)\n",
    "        if SFlabel[1] == 'ORGANIZATION':\n",
    "            org_str.append(SFlabel[0])\n",
    "            stripped_str1.append('-ORG-')\n",
    "        elif SFlabel[1] == 'PERSON':\n",
    "            name_str.append(SFlabel[0])\n",
    "            stripped_str1.append('-NAME-')\n",
    "        else:\n",
    "            stripped_str1.append(token)\n",
    "            stripped_str2.append(token)\n",
    "\n",
    "    output.append([docket_original[i],\n",
    "                   ' '.join(org_str),\n",
    "                   ' '.join(name_str),\n",
    "                   ' '.join(stripped_str1),\n",
    "                   ' '.join(stripped_str2)])\n",
    "    \n",
    "for i in range(5):\n",
    "    print('docket text:', i)\n",
    "    print(output[i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We may want to start here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3244, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Docket Text</th>\n",
       "      <th>Organization Portion</th>\n",
       "      <th>Name Portion</th>\n",
       "      <th>Identifying Org and Name</th>\n",
       "      <th>Stripped Org and Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPLAINT against Cardiogenics Holdings, Inc. ...</td>\n",
       "      <td>Cardiogenics Holdings , Inc. LG Capital Funding</td>\n",
       "      <td>( Steinmetz Michael Bowens Priscilla</td>\n",
       "      <td>COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...</td>\n",
       "      <td>COMPLAINT against filing fee $ 400 , receipt n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case assigned to Judge Ann M Donnelly and Magi...</td>\n",
       "      <td>Individual Practices of the assigned Judges</td>\n",
       "      <td>Ann M Donnelly Vera M. Scanlon Bowens Priscilla</td>\n",
       "      <td>Case assigned to Judge -NAME- -NAME- -NAME- an...</td>\n",
       "      <td>Case assigned to Judge and Magistrate Judge . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summons Issued as to Cardiogenics Holdings, In...</td>\n",
       "      <td>Cardiogenics Holdings</td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...</td>\n",
       "      <td>Summons Issued as to , Inc.. ( , ) ( Entered :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td></td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td></td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Original Docket Text  \\\n",
       "0  COMPLAINT against Cardiogenics Holdings, Inc. ...   \n",
       "1  Case assigned to Judge Ann M Donnelly and Magi...   \n",
       "2  Summons Issued as to Cardiogenics Holdings, In...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                              Organization Portion  \\\n",
       "0  Cardiogenics Holdings , Inc. LG Capital Funding   \n",
       "1      Individual Practices of the assigned Judges   \n",
       "2                            Cardiogenics Holdings   \n",
       "3                                                    \n",
       "4                                                    \n",
       "\n",
       "                                      Name Portion  \\\n",
       "0             ( Steinmetz Michael Bowens Priscilla   \n",
       "1  Ann M Donnelly Vera M. Scanlon Bowens Priscilla   \n",
       "2                                 Bowens Priscilla   \n",
       "3                                 Bowens Priscilla   \n",
       "4                                 Bowens Priscilla   \n",
       "\n",
       "                            Identifying Org and Name  \\\n",
       "0  COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...   \n",
       "1  Case assigned to Judge -NAME- -NAME- -NAME- an...   \n",
       "2  Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                               Stripped Org and Name  \n",
       "0  COMPLAINT against filing fee $ 400 , receipt n...  \n",
       "1  Case assigned to Judge and Magistrate Judge . ...  \n",
       "2  Summons Issued as to , Inc.. ( , ) ( Entered :...  \n",
       "3  NOTICE - emailed attorney regarding missing se...  \n",
       "4  In accordance with Rule 73 of the Federal Rule...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'docket_texts/train/DT/basic_df.pickle'\n",
    "#to load\n",
    "with open(filename, 'rb') as handle:\n",
    "    NER_df = pickle.load(handle)\n",
    "    \n",
    "new_df = NER_df.copy()\n",
    "print(new_df.shape)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize\n",
    "def normalize(docket_original):\n",
    "\n",
    "    url_regex1 = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "    url_regex2 = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    date_regex = '(\\d{1,2}[\\/ ](\\d{2}|January|Jan|February|Feb|March|Mar|April|Apr|May|May|June|Jun|July|Jul|August|Aug|September|Sep|October|Oct|November|Nov|December|Dec)[\\/ ]\\d{2,4})'\n",
    "    punct_regex = r\"[^a-zA-Z0-9]\"\n",
    "    num_regex = \"\\d+\"\n",
    "    extraspace_regex = \" +\"\n",
    "    docket_original = docket_original.split(' ')\n",
    "    docket_normalized = [text.lower() for text in docket_original]\n",
    "    docket_nourl1 = [re.sub(url_regex1, \"url\", text) for text in docket_normalized]\n",
    "    docket_nourl2 = [re.sub(url_regex2, \"url\", text) for text in docket_nourl1]\n",
    "    docket_nodate = [re.sub(date_regex, \"date\", text) for text in docket_nourl2]\n",
    "    docket_nopunct = [re.sub(punct_regex, \" \", text) for text in docket_nodate]\n",
    "    docket_nonum = [re.sub(num_regex, \" \", text) for text in docket_nopunct]\n",
    "    #new, remove if the last words are entered date\n",
    "    docket_noextraspace = re.sub(extraspace_regex, \" \", ' '.join(docket_nonum))\n",
    "    docket_no_entereddate = docket_noextraspace.replace('entered date', '')\n",
    "    \n",
    "    return docket_no_entereddate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 1.380718469619751 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "new_df['normalized'] = new_df['Stripped Org and Name'].apply(lambda x: normalize(x))\n",
    "print('took {} seconds'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complaint against filing fee receipt number was the disclosure statement on civil cover sheet completed yes filed by llc additional attachment s added on date civil cover sheet proposed summons  '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['normalized'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(docket_noextraspace):\n",
    "    return word_tokenize(docket_noextraspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.832021951675415 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "new_df['tokenize'] = new_df['normalized'].apply(tokenize)\n",
    "print('took {} seconds'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(docket_tokenized):  \n",
    "    return [word for word in docket_tokenized if word not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.268829345703125 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "new_df['nostop'] = new_df['tokenize'].apply(stopwords)\n",
    "print('took {} seconds'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is updated, comparing mannual_topics_20180828 and manual_topics_20180911 and manual_topics_20180919\n",
    "manual_topics_df = pd.read_csv('manual_topics_20180919.csv') \n",
    "manual_topics_df = manual_topics_df.apply(lambda x: x.astype(str).str.lower())\n",
    "manual_topics_dict = manual_topics_df.to_dict('list')\n",
    "for topic in manual_topics_dict.keys():\n",
    "    manual_topics_dict[topic] = [keyword for keyword in manual_topics_dict[topic] if keyword != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is updated, comparing mannual_topics_20180828 and manual_topics_20180911 and manual_topics_20180919\n",
    "manual_topics_df = pd.read_csv('manual_topics_20180919.csv') \n",
    "manual_topics_df = manual_topics_df.apply(lambda x: x.astype(str).str.lower())\n",
    "manual_topics_dict = manual_topics_df.to_dict('list')\n",
    "for topic in manual_topics_dict.keys():\n",
    "    manual_topics_dict[topic] = [keyword for keyword in manual_topics_dict[topic] if keyword != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output a list of topics\n",
    "def mannual_topic_assignment(text):\n",
    "    #text = text.split()\n",
    "    #print(text)\n",
    "    output = []\n",
    "    for topic in manual_topics_dict.keys():\n",
    "        for keyword in manual_topics_dict[topic]:\n",
    "            if ' '.join(text).find(keyword) != -1:\n",
    "                output.append(topic)\n",
    "    #print(output)\n",
    "    #if there's motion to dismiss, then remove noaction\n",
    "    if ' '.join(text).find('motion dismiss') != -1 and 'NoAction' in output:\n",
    "        output = list(set(output))\n",
    "        output.remove('NoAction')\n",
    "    return ', '.join(set(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "docket_texts_output = list(new_df['nostop'])\n",
    "\n",
    "docket_texts_output_DT = []\n",
    "topics_DT = []\n",
    "NoAction = []\n",
    "\n",
    "for text in docket_texts_output:\n",
    "    topic = mannual_topic_assignment(text)\n",
    "    #print(text, topic)\n",
    "    if topic != '':\n",
    "        docket_texts_output_DT.append('')\n",
    "        topics_DT.append(topic)\n",
    "        if 'NoAction' in topic:\n",
    "            NoAction.append(1)\n",
    "        else:\n",
    "            NoAction.append(0)\n",
    "    else:\n",
    "        docket_texts_output_DT.append(text)\n",
    "        topics_DT.append('')\n",
    "        NoAction.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3244, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Docket Text</th>\n",
       "      <th>Organization Portion</th>\n",
       "      <th>Name Portion</th>\n",
       "      <th>Identifying Org and Name</th>\n",
       "      <th>Stripped Org and Name</th>\n",
       "      <th>normalized</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>nostop</th>\n",
       "      <th>DT Topics</th>\n",
       "      <th>NoAction</th>\n",
       "      <th>Removed unnecessary POS &amp; vocab DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPLAINT against Cardiogenics Holdings, Inc. ...</td>\n",
       "      <td>Cardiogenics Holdings , Inc. LG Capital Funding</td>\n",
       "      <td>( Steinmetz Michael Bowens Priscilla</td>\n",
       "      <td>COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...</td>\n",
       "      <td>COMPLAINT against filing fee $ 400 , receipt n...</td>\n",
       "      <td>complaint against filing fee receipt number wa...</td>\n",
       "      <td>[complaint, against, filing, fee, receipt, num...</td>\n",
       "      <td>[complaint, filing, fee, receipt, number, disc...</td>\n",
       "      <td>Complaints, Service of Process, Motions</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case assigned to Judge Ann M Donnelly and Magi...</td>\n",
       "      <td>Individual Practices of the assigned Judges</td>\n",
       "      <td>Ann M Donnelly Vera M. Scanlon Bowens Priscilla</td>\n",
       "      <td>Case assigned to Judge -NAME- -NAME- -NAME- an...</td>\n",
       "      <td>Case assigned to Judge and Magistrate Judge . ...</td>\n",
       "      <td>case assigned to judge and magistrate judge pl...</td>\n",
       "      <td>[case, assigned, to, judge, and, magistrate, j...</td>\n",
       "      <td>[case, assigned, judge, magistrate, judge, ple...</td>\n",
       "      <td>NoAction</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summons Issued as to Cardiogenics Holdings, In...</td>\n",
       "      <td>Cardiogenics Holdings</td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...</td>\n",
       "      <td>Summons Issued as to , Inc.. ( , ) ( Entered :...</td>\n",
       "      <td>summons issued as to inc</td>\n",
       "      <td>[summons, issued, as, to, inc]</td>\n",
       "      <td>[summons, issued, inc]</td>\n",
       "      <td>Service of Process</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td></td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td>notice emailed attorney regarding missing seco...</td>\n",
       "      <td>[notice, emailed, attorney, regarding, missing...</td>\n",
       "      <td>[notice, emailed, attorney, regarding, missing...</td>\n",
       "      <td>NoAction, Notices</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td></td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td>in accordance with rule of the federal rules o...</td>\n",
       "      <td>[in, accordance, with, rule, of, the, federal,...</td>\n",
       "      <td>[accordance, rule, federal, rules, civil, proc...</td>\n",
       "      <td>Order, Notices, Motions, Judgment</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Original Docket Text  \\\n",
       "0  COMPLAINT against Cardiogenics Holdings, Inc. ...   \n",
       "1  Case assigned to Judge Ann M Donnelly and Magi...   \n",
       "2  Summons Issued as to Cardiogenics Holdings, In...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                              Organization Portion  \\\n",
       "0  Cardiogenics Holdings , Inc. LG Capital Funding   \n",
       "1      Individual Practices of the assigned Judges   \n",
       "2                            Cardiogenics Holdings   \n",
       "3                                                    \n",
       "4                                                    \n",
       "\n",
       "                                      Name Portion  \\\n",
       "0             ( Steinmetz Michael Bowens Priscilla   \n",
       "1  Ann M Donnelly Vera M. Scanlon Bowens Priscilla   \n",
       "2                                 Bowens Priscilla   \n",
       "3                                 Bowens Priscilla   \n",
       "4                                 Bowens Priscilla   \n",
       "\n",
       "                            Identifying Org and Name  \\\n",
       "0  COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...   \n",
       "1  Case assigned to Judge -NAME- -NAME- -NAME- an...   \n",
       "2  Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                               Stripped Org and Name  \\\n",
       "0  COMPLAINT against filing fee $ 400 , receipt n...   \n",
       "1  Case assigned to Judge and Magistrate Judge . ...   \n",
       "2  Summons Issued as to , Inc.. ( , ) ( Entered :...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                                          normalized  \\\n",
       "0  complaint against filing fee receipt number wa...   \n",
       "1  case assigned to judge and magistrate judge pl...   \n",
       "2                         summons issued as to inc     \n",
       "3  notice emailed attorney regarding missing seco...   \n",
       "4  in accordance with rule of the federal rules o...   \n",
       "\n",
       "                                            tokenize  \\\n",
       "0  [complaint, against, filing, fee, receipt, num...   \n",
       "1  [case, assigned, to, judge, and, magistrate, j...   \n",
       "2                     [summons, issued, as, to, inc]   \n",
       "3  [notice, emailed, attorney, regarding, missing...   \n",
       "4  [in, accordance, with, rule, of, the, federal,...   \n",
       "\n",
       "                                              nostop  \\\n",
       "0  [complaint, filing, fee, receipt, number, disc...   \n",
       "1  [case, assigned, judge, magistrate, judge, ple...   \n",
       "2                             [summons, issued, inc]   \n",
       "3  [notice, emailed, attorney, regarding, missing...   \n",
       "4  [accordance, rule, federal, rules, civil, proc...   \n",
       "\n",
       "                                 DT Topics  NoAction  \\\n",
       "0  Complaints, Service of Process, Motions         0   \n",
       "1                                 NoAction         1   \n",
       "2                       Service of Process         0   \n",
       "3                        NoAction, Notices         1   \n",
       "4        Order, Notices, Motions, Judgment         0   \n",
       "\n",
       "  Removed unnecessary POS & vocab DT  \n",
       "0                                     \n",
       "1                                     \n",
       "2                                     \n",
       "3                                     \n",
       "4                                     "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['DT Topics'] = pd.Series(topics_DT)\n",
    "new_df['NoAction'] = pd.Series(NoAction)\n",
    "new_df['Removed unnecessary POS & vocab DT'] = pd.Series(docket_texts_output_DT)\n",
    "print(new_df.shape)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(docket_nostop):\n",
    "    return ' '.join([WordNetLemmatizer().lemmatize(word, pos='v') for word in docket_nostop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 1.985579013824463 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3244, 12)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "new_df['lemmed'] = new_df['Removed unnecessary POS & vocab DT'].apply(lemm)\n",
    "print('took {} seconds'.format(time.time() - t0))\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docket_phrase2 = list(new_df['lemmed'])\n",
    "docket_phrase2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = 'docket_texts/train/DT/unigram_nltk_newsop2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# turn the lemmatized corpus into unigram sentences\n",
    "with codecs.open(unigram_sentences_filepath, 'w', encoding = 'utf_8') as f:\n",
    "    for sentence in docket_phrase2:\n",
    "        f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences = LineSentence(unigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model_filepath = 'docket_texts/train/DT/bigram_model_newsop2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# store our bigram model\n",
    "bigram_model = Phrases(unigram_sentences)\n",
    "bigram_model.save(bigram_model_filepath)\n",
    "    \n",
    "# load the finished model from disk if we don't want to run this again\n",
    "#bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sentences_filepath = 'docket_texts/train/DT/bigram_sentences_newsop2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# apply the bigram model, and write it to file\n",
    "with codecs.open(bigram_sentences_filepath, 'w', encoding = 'utf_8') as f:\n",
    "    for unigram_sentence in unigram_sentences:\n",
    "        bigram_sentence = ' '.join(bigram_model[unigram_sentence])\n",
    "        f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sentences = LineSentence(bigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unigram sentence:\n",
      "status report llc kehrli\n",
      "corporate disclosure statement\n",
      "status report propose brief schedule llc kehrli\n",
      "status report llc kehrli\n",
      "propose find fact llc kehrli\n",
      "witness list llc kehrli\n",
      "status report llc kehrli\n",
      "status report llc kehrli\n",
      "rule statement file llc\n",
      "civil cover sheet file\n",
      "\n",
      "Bigram sentence:\n",
      "status_report llc_kehrli\n",
      "corporate disclosure statement\n",
      "status_report propose brief schedule llc_kehrli\n",
      "status_report llc_kehrli\n",
      "propose_find fact llc_kehrli\n",
      "witness list llc_kehrli\n",
      "status_report llc_kehrli\n",
      "status_report llc_kehrli\n",
      "rule statement file llc\n",
      "civil_cover sheet file\n"
     ]
    }
   ],
   "source": [
    "print('\\nUnigram sentence:')\n",
    "for unigram_sentence in it.islice(unigram_sentences, 0, 10):\n",
    "    print(' '.join(unigram_sentence))\n",
    "print('\\nBigram sentence:')\n",
    "for bigram_sentence in it.islice(bigram_sentences, 0, 10):\n",
    "    print(' '.join(bigram_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_model_filepath = 'docket_texts/train/DT/trigram_model_newsop2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# again, using Phrases to attach more words to phrases already formed\n",
    "trigram_model = Phrases(bigram_sentences)\n",
    "trigram_model.save(trigram_model_filepath)\n",
    "\n",
    "# load the finished model from disk\n",
    "#trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = 'docket_texts/train/DT/trigram_sentences_newsop2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.95 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with codecs.open(trigram_sentences_filepath, 'w', encoding = 'utf_8') as f:\n",
    "    for bigram_sentence in bigram_sentences:\n",
    "        #print('Bi', bigram_sentence)\n",
    "        trigram_sentence = ' '.join(trigram_model[bigram_sentence])\n",
    "        #print('Tri', trigram_sentence)\n",
    "        f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "['', '', '', '', ''] \n",
      "\n",
      "\n",
      "UNIGRAM Sentence:\n",
      "status report llc kehrli\n",
      "corporate disclosure statement\n",
      "status report propose brief schedule llc kehrli\n",
      "status report llc kehrli\n",
      "propose find fact llc kehrli\n",
      "\n",
      "BIGRAM Sentence:\n",
      "status_report llc_kehrli\n",
      "corporate disclosure statement\n",
      "status_report propose brief schedule llc_kehrli\n",
      "status_report llc_kehrli\n",
      "propose_find fact llc_kehrli\n",
      "\n",
      "TRIGRAM Sentence:\n",
      "status_report llc_kehrli\n",
      "corporate_disclosure statement\n",
      "status_report propose brief schedule llc_kehrli\n",
      "status_report llc_kehrli\n",
      "propose_find fact llc_kehrli\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "finish = 5\n",
    "print('Original text:')\n",
    "print(docket_phrase2[start:finish], '\\n')\n",
    "\n",
    "print('\\nUNIGRAM Sentence:')\n",
    "for unigram_sentence in it.islice(unigram_sentences, start, finish):\n",
    "    print(' '.join(unigram_sentence))\n",
    "print('\\nBIGRAM Sentence:')\n",
    "for bigram_sentence in it.islice(bigram_sentences, start, finish):\n",
    "    print(' '.join(bigram_sentence))\n",
    "print('\\nTRIGRAM Sentence:')\n",
    "for trigram_sentence in it.islice(trigram_sentences, start, finish):\n",
    "    print(' '.join(trigram_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_transform(texts):\n",
    "    display = False\n",
    "    texts = str(texts)\n",
    "    trigram_output = ''\n",
    "    #print(texts)\n",
    "\n",
    "    remove_trigram = ['calendar_day', 'court_notice_intend', 'minute_entry_proceeding_hold', 'court_reportertranscriber_abovecaptioned_matter',\n",
    "                      'redaction_calendar_day', 'rule_statement', 'obtain_pacer', 'may_obtain_pacer', 'reportertranscriber_abovecaptioned_matter',\n",
    "                      'redact_transcript_deadline', 'send_chamber', \"official_transcript_notice_give\", \"notice_intent_request\", \"proceed_hold\", \n",
    "                      \"fee_receipt_number\", \"civil_procedure\", \"pursuant_frcp\", \"official_transcript_conference\", \n",
    "                      \"purchase_reportertranscriber_deadline_release\", \"et_al\", \"mail_chamber\", \"transcript_restriction\", \"redaction_transcript\", \n",
    "                      \"transcript_view_public_terminal\", \"transcript_make_remotely\", \"associated_et_al\", \"electronically_available_public_without\", \n",
    "                      \"genesys_id\", \"release_transcript_restriction\", \"adar_bay\", \"redaction_request_due\", \"new_york\", \"official_transcript_conference\", \n",
    "                      \"transcript_make_remotely\", \"transcript_proceeding_conference_hold\", \"redaction_transcript\",\n",
    "                      'affidavit_jr._c.p.a', 'corporate_parent', 'certain_underwriter', 'federal_rule_civil_procedure', 'redaction_request', \n",
    "                      'official_transcript', 'rule_disclosure', 'rule_corporate_disclosure', 'place_vault', 'public_without_redaction_calendar', \n",
    "                      'purchase_deadline_release_transcript', 'transcript_proceeding_hold', 'transcript_remotely_electronically_available',\n",
    "                      'minute_entry_hold', 'discovery_hear_hold', 'jury_trial_hold', \"sign_judge\",'place_vault']\n",
    "\n",
    "    if texts == None:\n",
    "        return None\n",
    "    \n",
    "    unigram_review = []\n",
    "    for word in texts.split():\n",
    "        unigram_review.append(word)\n",
    "    if display:\n",
    "        print('Uni: ', unigram_review)\n",
    "    bigram_review = bigram_model[unigram_review]\n",
    "    if display:\n",
    "        print('Bi: ', bigram_review)\n",
    "    trigram_review = trigram_model[bigram_review]\n",
    "    if display:\n",
    "        print('Tri: ', trigram_review)\n",
    "    trigram_review = [phrase for phrase in trigram_review if phrase not in remove_trigram]\n",
    "    if display:\n",
    "        print('Tri removed: ', trigram_review)\n",
    "    trigram_output += ' '.join(trigram_review)\n",
    "    \n",
    "    return trigram_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "docket_phrase3 = [trigram_transform(text) for text in docket_phrase2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '']\n",
      "['', '', '', '', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(docket_phrase2[:5])\n",
    "print(docket_phrase3[:5])\n",
    "len(set(docket_phrase3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3244, 13)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['phrases'] = pd.Series(docket_phrase3)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Original Docket Text', 'Organization Portion', 'Name Portion',\n",
       "       'Identifying Org and Name', 'Stripped Org and Name', 'normalized',\n",
       "       'tokenize', 'nostop', 'DT Topics', 'NoAction',\n",
       "       'Removed unnecessary POS & vocab DT', 'lemmed', 'phrases'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignal text: \n",
      "Case assigned to Judge Ann M Donnelly and Magistrate Judge Vera M. Scanlon. Please download and review the Individual Practices of the assigned Judges, located on our website. Attorneys are responsible for providing courtesy copies to judges where their Individual Practices require such. (Bowens, Priscilla) (Entered: 03/11/2016) \n",
      "\n",
      "org and name removed: \n",
      "Case assigned to Judge and Magistrate Judge . Please download and review the , located on our website . Attorneys are responsible for providing courtesy copies to judges where their Individual Practices require such . ( , ) ( Entered : 03/11/2016 ) \n",
      "\n",
      "normalized: \n",
      "case assigned to judge and magistrate judge please download and review the located on our website attorneys are responsible for providing courtesy copies to judges where their individual practices require such   \n",
      "\n",
      "stopwords removed: \n",
      "case assigned judge magistrate judge please download review located website attorneys responsible providing courtesy copies judges individual practices require \n",
      "\n",
      "after lemmetization: \n",
      " \n",
      "\n",
      "after phrase modeling: \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print('orignal text: ')\n",
    "print(new_df['Original Docket Text'].iloc[i], '\\n')\n",
    "print('org and name removed: ')\n",
    "print(new_df['Stripped Org and Name'].iloc[i], '\\n')\n",
    "print('normalized: ')\n",
    "print(new_df['normalized'].iloc[i], '\\n')\n",
    "print('stopwords removed: ')\n",
    "print(' '.join(new_df['nostop'].iloc[i]), '\\n')\n",
    "print('after lemmetization: ')\n",
    "print(new_df['lemmed'].iloc[i], '\\n')\n",
    "print('after phrase modeling: ')\n",
    "print(new_df['phrases'].iloc[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_pos = list(pd.read_excel('NLP_to_be_removed.xlsx', sheetname = 0, header = None)[0])\n",
    "remove_word = list(pd.read_excel('NLP_to_be_removed.xlsx', sheetname = 1, header = None)[0])\n",
    "remove_trigram = list(pd.read_excel('NLP_to_be_removed.xlsx', sheetname = 2, header = None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary(text):\n",
    "    new_text = []\n",
    "    text = text.split(' ')\n",
    "    for word in text:\n",
    "        if word not in remove_word and word not in remove_trigram:\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3244, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Docket Text</th>\n",
       "      <th>Organization Portion</th>\n",
       "      <th>Name Portion</th>\n",
       "      <th>Identifying Org and Name</th>\n",
       "      <th>Stripped Org and Name</th>\n",
       "      <th>normalized</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>nostop</th>\n",
       "      <th>DT Topics</th>\n",
       "      <th>NoAction</th>\n",
       "      <th>Removed unnecessary POS &amp; vocab DT</th>\n",
       "      <th>lemmed</th>\n",
       "      <th>phrases</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPLAINT against Cardiogenics Holdings, Inc. ...</td>\n",
       "      <td>Cardiogenics Holdings , Inc. LG Capital Funding</td>\n",
       "      <td>( Steinmetz Michael Bowens Priscilla</td>\n",
       "      <td>COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...</td>\n",
       "      <td>COMPLAINT against filing fee $ 400 , receipt n...</td>\n",
       "      <td>complaint against filing fee receipt number wa...</td>\n",
       "      <td>[complaint, against, filing, fee, receipt, num...</td>\n",
       "      <td>[complaint, filing, fee, receipt, number, disc...</td>\n",
       "      <td>Complaints, Service of Process, Motions</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case assigned to Judge Ann M Donnelly and Magi...</td>\n",
       "      <td>Individual Practices of the assigned Judges</td>\n",
       "      <td>Ann M Donnelly Vera M. Scanlon Bowens Priscilla</td>\n",
       "      <td>Case assigned to Judge -NAME- -NAME- -NAME- an...</td>\n",
       "      <td>Case assigned to Judge and Magistrate Judge . ...</td>\n",
       "      <td>case assigned to judge and magistrate judge pl...</td>\n",
       "      <td>[case, assigned, to, judge, and, magistrate, j...</td>\n",
       "      <td>[case, assigned, judge, magistrate, judge, ple...</td>\n",
       "      <td>NoAction</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summons Issued as to Cardiogenics Holdings, In...</td>\n",
       "      <td>Cardiogenics Holdings</td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...</td>\n",
       "      <td>Summons Issued as to , Inc.. ( , ) ( Entered :...</td>\n",
       "      <td>summons issued as to inc</td>\n",
       "      <td>[summons, issued, as, to, inc]</td>\n",
       "      <td>[summons, issued, inc]</td>\n",
       "      <td>Service of Process</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td></td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td>notice emailed attorney regarding missing seco...</td>\n",
       "      <td>[notice, emailed, attorney, regarding, missing...</td>\n",
       "      <td>[notice, emailed, attorney, regarding, missing...</td>\n",
       "      <td>NoAction, Notices</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td></td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td>in accordance with rule of the federal rules o...</td>\n",
       "      <td>[in, accordance, with, rule, of, the, federal,...</td>\n",
       "      <td>[accordance, rule, federal, rules, civil, proc...</td>\n",
       "      <td>Order, Notices, Motions, Judgment</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Original Docket Text  \\\n",
       "0  COMPLAINT against Cardiogenics Holdings, Inc. ...   \n",
       "1  Case assigned to Judge Ann M Donnelly and Magi...   \n",
       "2  Summons Issued as to Cardiogenics Holdings, In...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                              Organization Portion  \\\n",
       "0  Cardiogenics Holdings , Inc. LG Capital Funding   \n",
       "1      Individual Practices of the assigned Judges   \n",
       "2                            Cardiogenics Holdings   \n",
       "3                                                    \n",
       "4                                                    \n",
       "\n",
       "                                      Name Portion  \\\n",
       "0             ( Steinmetz Michael Bowens Priscilla   \n",
       "1  Ann M Donnelly Vera M. Scanlon Bowens Priscilla   \n",
       "2                                 Bowens Priscilla   \n",
       "3                                 Bowens Priscilla   \n",
       "4                                 Bowens Priscilla   \n",
       "\n",
       "                            Identifying Org and Name  \\\n",
       "0  COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...   \n",
       "1  Case assigned to Judge -NAME- -NAME- -NAME- an...   \n",
       "2  Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                               Stripped Org and Name  \\\n",
       "0  COMPLAINT against filing fee $ 400 , receipt n...   \n",
       "1  Case assigned to Judge and Magistrate Judge . ...   \n",
       "2  Summons Issued as to , Inc.. ( , ) ( Entered :...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                                          normalized  \\\n",
       "0  complaint against filing fee receipt number wa...   \n",
       "1  case assigned to judge and magistrate judge pl...   \n",
       "2                         summons issued as to inc     \n",
       "3  notice emailed attorney regarding missing seco...   \n",
       "4  in accordance with rule of the federal rules o...   \n",
       "\n",
       "                                            tokenize  \\\n",
       "0  [complaint, against, filing, fee, receipt, num...   \n",
       "1  [case, assigned, to, judge, and, magistrate, j...   \n",
       "2                     [summons, issued, as, to, inc]   \n",
       "3  [notice, emailed, attorney, regarding, missing...   \n",
       "4  [in, accordance, with, rule, of, the, federal,...   \n",
       "\n",
       "                                              nostop  \\\n",
       "0  [complaint, filing, fee, receipt, number, disc...   \n",
       "1  [case, assigned, judge, magistrate, judge, ple...   \n",
       "2                             [summons, issued, inc]   \n",
       "3  [notice, emailed, attorney, regarding, missing...   \n",
       "4  [accordance, rule, federal, rules, civil, proc...   \n",
       "\n",
       "                                 DT Topics  NoAction  \\\n",
       "0  Complaints, Service of Process, Motions         0   \n",
       "1                                 NoAction         1   \n",
       "2                       Service of Process         0   \n",
       "3                        NoAction, Notices         1   \n",
       "4        Order, Notices, Motions, Judgment         0   \n",
       "\n",
       "  Removed unnecessary POS & vocab DT lemmed phrases cleaned  \n",
       "0                                                            \n",
       "1                                                            \n",
       "2                                                            \n",
       "3                                                            \n",
       "4                                                            "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['cleaned'] = new_df['phrases'].apply(remove_unnecessary)\n",
    "print(new_df.shape)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are happy with the NLP process, START/STOP here\n",
    "\n",
    "### If you need to continue to merge with domain expert's answer key for the traning set, proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3203, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Docket Text</th>\n",
       "      <th>normalized</th>\n",
       "      <th>lemmed</th>\n",
       "      <th>phrases</th>\n",
       "      <th>DT Topics</th>\n",
       "      <th>NoAction</th>\n",
       "      <th>Action</th>\n",
       "      <th>If Action</th>\n",
       "      <th>Action revised</th>\n",
       "      <th>If Action revised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>SEALED DOCUMENT placed in vault.(nm) (Entered:...</td>\n",
       "      <td>sealed document placed in vault nm entered date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoAction, Motions</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>Please be advised that Judge Abrams Courtroom ...</td>\n",
       "      <td>please be advised that judge abrams courtroom ...</td>\n",
       "      <td>please advise judge abrams courtroom chamber m...</td>\n",
       "      <td>please advise judge abrams courtroom chamber m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>MOTION for Andrew John Estes and Simona Gory t...</td>\n",
       "      <td>motion for and to withdraw as attorney for and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>MEMO ENDORSEMENT granting 204 MOTION FOR LEAVE...</td>\n",
       "      <td>memo endorsement granting motion for leave to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions, Order</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>SIXTH REVISED SCHEDULING ORDER: Expert Discove...</td>\n",
       "      <td>sixth revised scheduling order expert discover...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other Answers, Discovery, Order, Motions</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>ENDORSED LETTER addressed to Magistrate Judge ...</td>\n",
       "      <td>endorsed letter addressed to magistrate judge ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discovery, Notices, Service of Process, Letter...</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>ENDORSED LETTER addressed to Magistrate Judge ...</td>\n",
       "      <td>endorsed letter addressed to magistrate judge ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discovery, Notices, Service of Process, Letter...</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>MOTION for Randall T. Adams to Withdraw as Att...</td>\n",
       "      <td>motion for to withdraw as attorney for plainti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>MEMO ENDORSEMENT ON MOTION FOR LEAVE TO WITHDR...</td>\n",
       "      <td>memo endorsement on motion for leave to withdr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>MOTION for Joseph P. Fishman to Withdraw as At...</td>\n",
       "      <td>motion for to withdraw as attorney document fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions, Service of Process</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>MEMO ENDORSED on MOTION FOR LEAVE TO WITHDRAW ...</td>\n",
       "      <td>memo endorsed on motion for leave to withdraw ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions, Notices, Order</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>ENDORSED LETTER addressed to Judge Ronnie Abra...</td>\n",
       "      <td>endorsed letter addressed to judge from dated ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service of Process, Notices, Motions, Letter a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>Minute Entry for proceedings held before Magis...</td>\n",
       "      <td>minute entry for proceedings held before magis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoAction, Notices</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>SEVENTH REVISED SCHEDULING ORDER: The parties'...</td>\n",
       "      <td>seventh revised scheduling order the parties p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions, Discovery, Order, Letter and Response</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>STIPULATION OF VOLUNTARY DISMISSAL It is hereb...</td>\n",
       "      <td>stipulation of voluntary dismissal it is hereb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notices, Motions</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>STIPULATION OF DISMISSAL WITH PREJUDICE: that ...</td>\n",
       "      <td>stipulation of dismissal with prejudice that t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions, Notices, Order</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>Terminate Transcript Deadlines (tn) (Entered: ...</td>\n",
       "      <td>terminate transcript deadlines tn entered date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NoAction, Notices</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>STIPULATION AND ORDER MODIFYING STIPULATED CON...</td>\n",
       "      <td>stipulation and order modifying stipulated con...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notices, Order</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>NOTICE TO ATTORNEY TO RETRIEVE SEALED MATERIAL...</td>\n",
       "      <td>notice to attorney to retrieve sealed material...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notices, Motions</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney; Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>SEALED MATERIALS RETRIEVED: Document(s) 95 wer...</td>\n",
       "      <td>sealed materials retrieved document s were ret...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motions</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "      <td>Y</td>\n",
       "      <td>Attorney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Original Docket Text  \\\n",
       "3183  SEALED DOCUMENT placed in vault.(nm) (Entered:...   \n",
       "3184  Please be advised that Judge Abrams Courtroom ...   \n",
       "3185  MOTION for Andrew John Estes and Simona Gory t...   \n",
       "3186  MEMO ENDORSEMENT granting 204 MOTION FOR LEAVE...   \n",
       "3187  SIXTH REVISED SCHEDULING ORDER: Expert Discove...   \n",
       "3188  ENDORSED LETTER addressed to Magistrate Judge ...   \n",
       "3189  ENDORSED LETTER addressed to Magistrate Judge ...   \n",
       "3190  MOTION for Randall T. Adams to Withdraw as Att...   \n",
       "3191  MEMO ENDORSEMENT ON MOTION FOR LEAVE TO WITHDR...   \n",
       "3192  MOTION for Joseph P. Fishman to Withdraw as At...   \n",
       "3193  MEMO ENDORSED on MOTION FOR LEAVE TO WITHDRAW ...   \n",
       "3194  ENDORSED LETTER addressed to Judge Ronnie Abra...   \n",
       "3195  Minute Entry for proceedings held before Magis...   \n",
       "3196  SEVENTH REVISED SCHEDULING ORDER: The parties'...   \n",
       "3197  STIPULATION OF VOLUNTARY DISMISSAL It is hereb...   \n",
       "3198  STIPULATION OF DISMISSAL WITH PREJUDICE: that ...   \n",
       "3199  Terminate Transcript Deadlines (tn) (Entered: ...   \n",
       "3200  STIPULATION AND ORDER MODIFYING STIPULATED CON...   \n",
       "3201  NOTICE TO ATTORNEY TO RETRIEVE SEALED MATERIAL...   \n",
       "3202  SEALED MATERIALS RETRIEVED: Document(s) 95 wer...   \n",
       "\n",
       "                                             normalized  \\\n",
       "3183   sealed document placed in vault nm entered date    \n",
       "3184  please be advised that judge abrams courtroom ...   \n",
       "3185  motion for and to withdraw as attorney for and...   \n",
       "3186  memo endorsement granting motion for leave to ...   \n",
       "3187  sixth revised scheduling order expert discover...   \n",
       "3188  endorsed letter addressed to magistrate judge ...   \n",
       "3189  endorsed letter addressed to magistrate judge ...   \n",
       "3190  motion for to withdraw as attorney for plainti...   \n",
       "3191  memo endorsement on motion for leave to withdr...   \n",
       "3192  motion for to withdraw as attorney document fi...   \n",
       "3193  memo endorsed on motion for leave to withdraw ...   \n",
       "3194  endorsed letter addressed to judge from dated ...   \n",
       "3195  minute entry for proceedings held before magis...   \n",
       "3196  seventh revised scheduling order the parties p...   \n",
       "3197  stipulation of voluntary dismissal it is hereb...   \n",
       "3198  stipulation of dismissal with prejudice that t...   \n",
       "3199    terminate transcript deadlines tn entered date    \n",
       "3200  stipulation and order modifying stipulated con...   \n",
       "3201  notice to attorney to retrieve sealed material...   \n",
       "3202  sealed materials retrieved document s were ret...   \n",
       "\n",
       "                                                 lemmed  \\\n",
       "3183                                                NaN   \n",
       "3184  please advise judge abrams courtroom chamber m...   \n",
       "3185                                                NaN   \n",
       "3186                                                NaN   \n",
       "3187                                                NaN   \n",
       "3188                                                NaN   \n",
       "3189                                                NaN   \n",
       "3190                                                NaN   \n",
       "3191                                                NaN   \n",
       "3192                                                NaN   \n",
       "3193                                                NaN   \n",
       "3194                                                NaN   \n",
       "3195                                                NaN   \n",
       "3196                                                NaN   \n",
       "3197                                                NaN   \n",
       "3198                                                NaN   \n",
       "3199                                                NaN   \n",
       "3200                                                NaN   \n",
       "3201                                                NaN   \n",
       "3202                                                NaN   \n",
       "\n",
       "                                                phrases  \\\n",
       "3183                                                NaN   \n",
       "3184  please advise judge abrams courtroom chamber m...   \n",
       "3185                                                NaN   \n",
       "3186                                                NaN   \n",
       "3187                                                NaN   \n",
       "3188                                                NaN   \n",
       "3189                                                NaN   \n",
       "3190                                                NaN   \n",
       "3191                                                NaN   \n",
       "3192                                                NaN   \n",
       "3193                                                NaN   \n",
       "3194                                                NaN   \n",
       "3195                                                NaN   \n",
       "3196                                                NaN   \n",
       "3197                                                NaN   \n",
       "3198                                                NaN   \n",
       "3199                                                NaN   \n",
       "3200                                                NaN   \n",
       "3201                                                NaN   \n",
       "3202                                                NaN   \n",
       "\n",
       "                                              DT Topics  NoAction Action  \\\n",
       "3183                                  NoAction, Motions         1      N   \n",
       "3184                                                NaN         0      Y   \n",
       "3185                                            Motions         0      Y   \n",
       "3186                                     Motions, Order         0      Y   \n",
       "3187           Other Answers, Discovery, Order, Motions         0      Y   \n",
       "3188  Discovery, Notices, Service of Process, Letter...         0      Y   \n",
       "3189  Discovery, Notices, Service of Process, Letter...         0      Y   \n",
       "3190                                            Motions         0      Y   \n",
       "3191                                            Motions         0      Y   \n",
       "3192                        Motions, Service of Process         0      Y   \n",
       "3193                            Motions, Notices, Order         0      Y   \n",
       "3194  Service of Process, Notices, Motions, Letter a...         0      Y   \n",
       "3195                                  NoAction, Notices         1      N   \n",
       "3196     Motions, Discovery, Order, Letter and Response         0      Y   \n",
       "3197                                   Notices, Motions         0      Y   \n",
       "3198                            Motions, Notices, Order         0      Y   \n",
       "3199                                  NoAction, Notices         1      N   \n",
       "3200                                     Notices, Order         0      Y   \n",
       "3201                                   Notices, Motions         0      Y   \n",
       "3202                                            Motions         0      Y   \n",
       "\n",
       "                If Action Action revised    If Action revised  \n",
       "3183                  NaN              N                  NaN  \n",
       "3184  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3185             Attorney              Y             Attorney  \n",
       "3186             Attorney              Y             Attorney  \n",
       "3187  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3188  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3189  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3190             Attorney              Y             Attorney  \n",
       "3191             Attorney              Y             Attorney  \n",
       "3192  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3193             Attorney              Y             Attorney  \n",
       "3194             Attorney              Y             Attorney  \n",
       "3195                  NaN              N                  NaN  \n",
       "3196  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3197  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3198             Attorney              Y             Attorney  \n",
       "3199                  NaN              N                  NaN  \n",
       "3200  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3201  Attorney; Assistant              Y  Attorney; Assistant  \n",
       "3202             Attorney              Y             Attorney  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filename = r'E:\\WinUser\\Documents\\Python Code\\AI Paralegal\\docket_texts\\Train\\DT\\train_tempfile.xlsx'\n",
    "old_df = pd.read_excel(train_filename)\n",
    "\n",
    "print(old_df.shape)\n",
    "old_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3203, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Original Docket Text', 'normalized', 'lemmed', 'phrases', 'DT Topics',\n",
       "       'NoAction', 'Action', 'If Action', 'Action revised',\n",
       "       'If Action revised'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(old_df.drop_duplicates().shape)\n",
    "old_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3203, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Original Docket Text', 'Organization Portion', 'Name Portion',\n",
       "       'Identifying Org and Name', 'Stripped Org and Name', 'normalized',\n",
       "       'tokenize', 'nostop', 'DT Topics', 'NoAction',\n",
       "       'Removed unnecessary POS & vocab DT', 'lemmed', 'phrases', 'cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_df[['Original Docket Text', 'normalized', 'lemmed', 'phrases', 'DT Topics']].drop_duplicates().shape)\n",
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3203, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Docket Text</th>\n",
       "      <th>normalized</th>\n",
       "      <th>lemmed</th>\n",
       "      <th>phrases</th>\n",
       "      <th>DT Topics</th>\n",
       "      <th>NoAction</th>\n",
       "      <th>Action</th>\n",
       "      <th>If Action</th>\n",
       "      <th>Action revised</th>\n",
       "      <th>If Action revised</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>Appeal Record Sent to USCA (Electronic File). ...</td>\n",
       "      <td>appeal record sent to usca electronic file cer...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Complaints, Letter and Response, Other Answers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Original Docket Text  \\\n",
       "2319  Appeal Record Sent to USCA (Electronic File). ...   \n",
       "\n",
       "                                             normalized lemmed phrases  \\\n",
       "2319  appeal record sent to usca electronic file cer...                  \n",
       "\n",
       "                                              DT Topics  NoAction Action  \\\n",
       "2319  Complaints, Letter and Response, Other Answers...       NaN    NaN   \n",
       "\n",
       "     If Action Action revised If Action revised     _merge  \n",
       "2319       NaN            NaN               NaN  left_only  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newer_df = new_df[['Original Docket Text', 'normalized', 'lemmed', 'phrases', 'DT Topics']].drop_duplicates().merge(old_df[['Original Docket Text', 'NoAction', 'Action', 'If Action', 'Action revised', 'If Action revised']], \n",
    "                                                                                                                    on = 'Original Docket Text', how = 'left', indicator = True)\n",
    "print(newer_df.shape)\n",
    "newer_df[newer_df['_merge'] != 'both'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Original Docket Text    Appeal Record Sent to USCA (Electronic File). ...\n",
       "normalized              appeal record sent to usca electronic file cer...\n",
       "lemmed                                                                NaN\n",
       "phrases                                                               NaN\n",
       "DT Topics               Notices, Order, Letter and Response, Judgment,...\n",
       "NoAction                                                                0\n",
       "Action                                                                NaN\n",
       "If Action                                                             NaN\n",
       "Action revised                                                        NaN\n",
       "If Action revised                                                     NaN\n",
       "Name: 2319, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.iloc[2319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Original Docket Text                  Appeal Record Sent to USCA (Electronic File). ...\n",
       "Organization Portion                  World Trade Company Silverstein Development Co...\n",
       "Name Portion                          Francis M. Lynch Swanke Hayden Connell Archete...\n",
       "Identifying Org and Name              Appeal Record Sent to USCA ( Electronic File )...\n",
       "Stripped Org and Name                 Appeal Record Sent to USCA ( Electronic File )...\n",
       "normalized                            appeal record sent to usca electronic file cer...\n",
       "tokenize                              [appeal, record, sent, to, usca, electronic, f...\n",
       "nostop                                [appeal, record, sent, usca, electronic, file,...\n",
       "DT Topics                             Complaints, Letter and Response, Other Answers...\n",
       "NoAction                                                                              0\n",
       "Removed unnecessary POS & vocab DT                                                     \n",
       "lemmed                                                                                 \n",
       "phrases                                                                                \n",
       "cleaned                                                                                \n",
       "Name: 2352, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Original Docket Text'].apply(len).sort_values(ascending = False)\n",
    "new_df.iloc[2352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complaints, Letter and Response, Other Answers, Service of Process, Judgment, Order, Notices, Answers to Complaints, Motions\n",
      "Notices, Order, Letter and Response, Judgment, Answers to Complaints, Other Answers, Complaints, Motions, Service of Process\n"
     ]
    }
   ],
   "source": [
    "print(new_df['DT Topics'].iloc[2352])\n",
    "print(old_df['DT Topics'].iloc[2319])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[2352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'docket_texts/train/DT/basic_cleaned_with_labels.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save\n",
    "with open(filename, 'wb') as handle: \n",
    "    pickle.dump(new_df, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you need domain expert to check your work, continue. Otherwise, STOP here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[['Original Docket Text', 'normalized', 'DT Topics', 'lemmed', 'phrases']].drop_duplicates().to_csv('Check if keywords working.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape before dedupe: {}'.format(new_df.shape))\n",
    "print('shape after dedupe: {}'.format(new_df[['Original Docket Text', 'normalized', 'DT Topics', 'lemmed', 'phrases']].drop_duplicates().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chris_file = pd.read_excel(r'temporary file - Sept 19.xlsx')\n",
    "print(chris_file.shape)\n",
    "chris_file.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_df = new_df[['Original Docket Text', 'normalized', 'lemmed', 'phrases', 'DT Topics', 'NoAction']].drop_duplicates().merge(chris_file[['Original Docket Text', 'Action', 'If Action']], on = 'Original Docket Text', how = 'left')\n",
    "print(another_df.shape)\n",
    "another_df.tail(1)\n",
    "#another_df.to_excel('tempfile.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_df['Action revised'] = np.where(another_df['NoAction'] == 1, 'N', another_df['Action'])\n",
    "another_df['If Action revised'] = np.where(another_df['NoAction'] == 1, '', another_df['If Action'])\n",
    "\n",
    "another_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to check\n",
    "another_df.to_excel('tempfile.xlsx', index = False)\n",
    "#applying methodology to the testing file is at another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
