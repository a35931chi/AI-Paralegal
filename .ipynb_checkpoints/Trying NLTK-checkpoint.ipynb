{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Goal:  \n",
    "Using existing NLP and LDA methodologies to perform topic modeling on docket texts. Three hyperparameters to consider:\n",
    "1. to remove organization or not in docket texts, so organizations themselves won't become topics.\n",
    "2. to remove names or not in docket texts, so names themselves won't become topics.\n",
    "3. variations in topic numbers: [2, 3, 5, 10]\n",
    "\n",
    "Will then perform visualizations and model summary output on every permutation/iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "#visualization libraries\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "java_path = 'C:/Program Files/Java/jdk-10.0.1/bin/java.exe'\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import corpus/docket texts from html to pandas DataFrame\n",
    "def grab_dockets():\n",
    "    files = []\n",
    "    #get all .html files in the folder (all docket files are in .html)\n",
    "    for file in os.listdir('docket_texts/'):\n",
    "        if file.endswith('.html'):\n",
    "            files.append(os.path.join('docket_texts/', file))\n",
    "\n",
    "    df_docket_texts = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(files)): #gather all docket texts\n",
    "    #for i in [0, 1]: #for testing purposes\n",
    "        \n",
    "        content = codecs.open(files[i], 'r', 'utf-8').read()\n",
    "        #use beautiful soup to get the case ID\n",
    "        soup = BeautifulSoup(content, 'lxml')\n",
    "        case_id = str(soup.find_all('h3'))    \n",
    "        bookmark1 = case_id.find('CASE #:') + len('CASE #:')\n",
    "        bookmark2 = case_id.find('</h3>')\n",
    "        case_id = case_id[bookmark1:bookmark2]\n",
    "\n",
    "        #use pandas to grab tables in the html files\n",
    "        docket_tables = pd.read_html(content)\n",
    "\n",
    "        #error checking: gotta do this because there's different length of docket_list/\n",
    "        #usually docket texts are in docket_list[3], but not always\n",
    "        n = 0\n",
    "        while docket_tables[n].isin(['Docket Text']).sum().sum() == 0:\n",
    "            #print(n, docket_tables[n].isin(['Docket Text']).sum().sum())\n",
    "            n += 1\n",
    "                        \n",
    "        #print(i, files[i])\n",
    "        #print(docket_tables[n].head())\n",
    "\n",
    "        #docket_tables[n] is the docket text table\n",
    "        new_header = docket_tables[n].iloc[0]\n",
    "        docket_tables[n] = docket_tables[n][1:]\n",
    "        docket_tables[n].columns = new_header\n",
    "        \n",
    "        docket_tables[n]['#'] = pd.to_numeric(docket_tables[n]['#'],\n",
    "                                              downcast = 'signed', errors = 'coerce')\n",
    "        docket_tables[n]['Date Filed'] = pd.to_datetime(docket_tables[n]['Date Filed'])\n",
    "        docket_tables[n]['Case ID'] = case_id\n",
    "\n",
    "        df_docket_texts = pd.concat([df_docket_texts, docket_tables[n]])\n",
    "    #reorder a column\n",
    "    cols = list(df_docket_texts.columns)\n",
    "    df_docket_texts = df_docket_texts[[cols[-1]] + cols[:-1]]\n",
    "    \n",
    "    print('current docket text table size/shape: {}'.format(df_docket_texts.shape))\n",
    "    return df_docket_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n",
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\bs4\\builder\\_lxml.py:250: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  self.parser.feed(markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current docket text table size/shape: (3244, 4)\n",
      "docket text 0\n",
      "COMPLAINT against Cardiogenics Holdings, Inc. filing fee $ 400, receipt number 0207-8445206 Was the Disclosure Statement on Civil Cover Sheet completed -YES,, filed by LG Capital Funding, LLC. (Steinmetz, Michael) (Additional attachment(s) added on 3/11/2016: # 1 Civil Cover Sheet, # 2 Proposed Summons) (Bowens, Priscilla). (Entered: 03/10/2016) \n",
      "\n",
      "docket text 1\n",
      "Case assigned to Judge Ann M Donnelly and Magistrate Judge Vera M. Scanlon. Please download and review the Individual Practices of the assigned Judges, located on our website. Attorneys are responsible for providing courtesy copies to judges where their Individual Practices require such. (Bowens, Priscilla) (Entered: 03/11/2016) \n",
      "\n",
      "docket text 2\n",
      "Summons Issued as to Cardiogenics Holdings, Inc.. (Bowens, Priscilla) (Entered: 03/11/2016) \n",
      "\n",
      "docket text 3\n",
      "NOTICE - emailed attorney regarding missing second page of the civil cover sheet. (Bowens, Priscilla) (Entered: 03/11/2016) \n",
      "\n",
      "docket text 4\n",
      "In accordance with Rule 73 of the Federal Rules of Civil Procedure and Local Rule 73.1, the parties are notified that if all parties consent a United States magistrate judge of this court is available to conduct all proceedings in this civil action including a (jury or nonjury) trial and to order the entry of a final judgment. Attached to the Notice is a blank copy of the consent form that should be filled out, signed and filed electronically only if all parties wish to consent. The form may also be accessed at the following link: http://www.uscourts.gov/uscourts/FormsAndFees/Forms/AO085.pdf. You may withhold your consent without adverse substantive consequences. Do NOT return or file the consent unless all parties have signed the consent. (Bowens, Priscilla) (Entered: 03/11/2016) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = grab_dockets()\n",
    "docket_original = list(df['Docket Text'])\n",
    "for i in range(5):\n",
    "    print('docket text {}'.format(i))\n",
    "    print(docket_original[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 36min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_to_model = r'C:\\Users\\inves\\AppData\\Local\\Programs\\Python\\Python35\\Lib\\site-packages\\nltk\\stanford-ner-2018-02-27\\classifiers\\english.all.3class.distsim.crf.ser.gz'\n",
    "path_to_jar = r'C:\\Users\\inves\\AppData\\Local\\Programs\\Python\\Python35\\Lib\\site-packages\\nltk\\stanford-ner-2018-02-27\\stanford-ner.jar'\n",
    "tagger = StanfordNERTagger(path_to_model, path_to_jar = path_to_jar)\n",
    "\n",
    "output = []\n",
    "#length = 100 \n",
    "length = len(docket_original)\n",
    "for i in range(length):\n",
    "    org_str = []\n",
    "    name_str = []\n",
    "    stripped_str1 = []\n",
    "    stripped_str2 = []\n",
    "    tokens = nltk.tokenize.word_tokenize(docket_original[i])\n",
    "    for label in tagger.tag(tokens):\n",
    "        #print(label)\n",
    "        if label[1] == 'ORGANIZATION':\n",
    "            org_str.append(label[0])\n",
    "            stripped_str1.append('-ORG-')\n",
    "        elif label[1] == 'PERSON':\n",
    "            name_str.append(label[0])\n",
    "            stripped_str1.append('-NAME-')\n",
    "        else:\n",
    "            stripped_str1.append(label[0])\n",
    "            stripped_str2.append(label[0])\n",
    "    \n",
    "    output.append([docket_original[i],\n",
    "                   ' '.join(org_str),\n",
    "                   ' '.join(name_str),\n",
    "                   ' '.join(stripped_str1),\n",
    "                   ' '.join(stripped_str2)])\n",
    "    \n",
    "new_df = pd.DataFrame(output, columns = ['Original Text', 'Org Part', 'Name Part', 'Stripped Txt', 'RTW Txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Original Text  \\\n",
      "0  COMPLAINT against Cardiogenics Holdings, Inc. ...   \n",
      "1  Case assigned to Judge Ann M Donnelly and Magi...   \n",
      "2  Summons Issued as to Cardiogenics Holdings, In...   \n",
      "3  NOTICE - emailed attorney regarding missing se...   \n",
      "4  In accordance with Rule 73 of the Federal Rule...   \n",
      "\n",
      "                                          Org Part  \\\n",
      "0  Cardiogenics Holdings , Inc. LG Capital Funding   \n",
      "1      Individual Practices of the assigned Judges   \n",
      "2                            Cardiogenics Holdings   \n",
      "3                                                    \n",
      "4                                                    \n",
      "\n",
      "                                         Name Part  \\\n",
      "0             ( Steinmetz Michael Bowens Priscilla   \n",
      "1  Ann M Donnelly Vera M. Scanlon Bowens Priscilla   \n",
      "2                                 Bowens Priscilla   \n",
      "3                                 Bowens Priscilla   \n",
      "4                                 Bowens Priscilla   \n",
      "\n",
      "                                        Stripped Txt  \\\n",
      "0  COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...   \n",
      "1  Case assigned to Judge -NAME- -NAME- -NAME- an...   \n",
      "2  Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...   \n",
      "3  NOTICE - emailed attorney regarding missing se...   \n",
      "4  In accordance with Rule 73 of the Federal Rule...   \n",
      "\n",
      "                                             RTW Txt  \n",
      "0  COMPLAINT against filing fee $ 400 , receipt n...  \n",
      "1  Case assigned to Judge and Magistrate Judge . ...  \n",
      "2  Summons Issued as to , Inc.. ( , ) ( Entered :...  \n",
      "3  NOTICE - emailed attorney regarding missing se...  \n",
      "4  In accordance with Rule 73 of the Federal Rule...  \n"
     ]
    }
   ],
   "source": [
    "print(new_df.head())\n",
    "docket_text_list = list(new_df['RTW Txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess1(text):\n",
    "    text = text.replace('-', '')\n",
    "    text = text.replace('(', ' ')\n",
    "    text = text.replace(')', ' ')\n",
    "    text = text.replace('(s)', 's')\n",
    "    text = text.replace('*', '')\n",
    "    return text\n",
    "\n",
    "def text_preprocess2(text):\n",
    "    text = text.replace('.', '')\n",
    "    return text\n",
    "\n",
    "def remove_stop(sentence):\n",
    "    output = []\n",
    "    for word in sentence.split():\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            output.append(word)\n",
    "    return ' '.join(output)\n",
    "\n",
    "keywords = pd.read_csv('docket_texts/keywords.csv', header = None)\n",
    "keywords.columns = ['keywords']\n",
    "keyword_list = list(keywords['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case assigned to judge and magistrate judge . please download and review the , located on our website . attorneys are responsible for providing courtesy copies to judges where their individual practices require such .   ,     entered : 03112016  \n",
      "3244\n"
     ]
    }
   ],
   "source": [
    "docket_text_list = [text_preprocess1(sentence).lower() for sentence in docket_text_list]\n",
    "print(docket_text_list[1])\n",
    "print(len(docket_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "    def split(self,text):\n",
    "\n",
    "        # split into single sentence\n",
    "        sentences = self.splitter.tokenize(text)\n",
    "        # tokenization in each sentences\n",
    "        tokens = [self.tokenizer.tokenize(remove_stop(sent)) for sent in sentences]\n",
    "        return tokens\n",
    "\n",
    "\n",
    "class LemmatizationWithPOSTagger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_wordnet_pos(self,treebank_tag):\n",
    "        \"\"\"\n",
    "        return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n",
    "        \"\"\"\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            # As default pos in lemmatization is Noun\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    def pos_tag(self,tokens):\n",
    "        # find the pos tagginf for each tokens [('What', 'WP'), ('can', 'MD'), ('I', 'PRP') ....\n",
    "        pos_tokens = [nltk.pos_tag(token) for token in tokens]\n",
    "\n",
    "        # lemmatization using pos tagg   \n",
    "        # convert into feature set of [('What', 'What', ['WP']), ('can', 'can', ['MD']), ... ie [original WORD, Lemmatized word, POS tag]\n",
    "        pos_tokens = [ [(word, lemmatizer.lemmatize(word,self.get_wordnet_pos(pos_tag)), [pos_tag]) for (word,pos_tag) in pos] for pos in pos_tokens]\n",
    "        return pos_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "splitter = Splitter()\n",
    "lemmatization_using_pos_tagger = LemmatizationWithPOSTagger()\n",
    "\n",
    "lemma_docket_text_list = []\n",
    "for docket_text in docket_text_list:\n",
    "    #step 1 split document into sentence followed by tokenization\n",
    "    tokens = splitter.split(docket_text)\n",
    "\n",
    "    #step 2 lemmatization using pos tagger \n",
    "    lemma_pos_token = lemmatization_using_pos_tagger.pos_tag(tokens)\n",
    "    lemma_docket_text_list.append(lemma_pos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244\n",
      "3\n",
      "22\n",
      "('complaint', 'complaint', ['NN'])\n",
      "complaint\n"
     ]
    }
   ],
   "source": [
    "print(len(lemma_docket_text_list)) #docket text document level\n",
    "print(len(lemma_docket_text_list[0])) #docket text sentence level\n",
    "print(len(lemma_docket_text_list[0][0])) #docket text word level\n",
    "print(lemma_docket_text_list[0][0][0]) #docket text token level\n",
    "print(lemma_docket_text_list[0][0][0][0]) #docket text tuple level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets do a collection of what we have\n",
    "collection = {}\n",
    "for lemma_pos_token in lemma_docket_text_list:\n",
    "    for sentence in lemma_pos_token:\n",
    "        for token in sentence:\n",
    "            #print(token[2][0])\n",
    "            if token[2][0] not in list(collection.keys()):\n",
    "                collection[token[2][0]] = []\n",
    "                collection[token[2][0]].append(token[1])\n",
    "            else:\n",
    "                if token[1] not in collection[token[2][0]]:\n",
    "                    collection[token[2][0]].append(token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict([ (k, pd.Series(v)) for k, v in collection.items()])).to_csv('NLP_pos.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['complaint file fee receipt number disclosure statement civil cover sheet complete yes file llc .', 'additional attachment add civil cover sheet proposed summons .', 'enter'], ['case assign judge magistrate judge .', 'please download review locate website .', 'attorney responsible provide courtesy copy judge individual practice require .', 'enter'], ['summons issue inc.. enter'], ['notice email attorney regard miss second page civil cover sheet .', 'enter'], ['accordance rule federal rule civil procedure local rule party notify party consent united state magistrate judge court available conduct proceeding civil action include jury nonjury trial order entry final judgment .', 'attach notice blank copy consent form fill sign file electronically party wish consent .', 'form may also access follow link http www.uscourts.govuscourtsformsandfeesformsao085.pdf .', 'may withhold consent without adverse substantive consequence .', 'return file consent unless party sign consent .', 'enter'], ['attorney case open filing check quality control .', 'see attachment correction make .', 'enter'], ['notice appearance behalf llc aty notice kehrli enter'], ['exhibit backend note llc .', 'related document complaint file llc .', 'enter'], ['exhibit b ta letter llc .', 'related document complaint file llc .', 'enter'], ['exhibit c notice conversion llc .', 'related document complaint file llc .', 'enter']]\n",
      "Wall time: 61.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "remove_pos = [\"``\", \"NNPS\", \"NNP\", \"CD\", '#', '$', \"''\", \",\", \"0\", \":\"]\n",
    "#rebuild corpus\n",
    "docket_texts_output = [] #ultimate output after cleaning\n",
    "\n",
    "for lemma_pos_token in lemma_docket_text_list:\n",
    "    docket_text_output = [] \n",
    "    for sentence in lemma_pos_token:\n",
    "        sentence_output = []\n",
    "        for token in sentence:\n",
    "            if token[2][0] not in remove_pos: #if the pos is not in the remove_pos list\n",
    "                sentence_output.append(token[1]) #append the the sentence\n",
    "        docket_text_output.append(' '.join(sentence_output))\n",
    "    docket_texts_output.append(docket_text_output)\n",
    "print(docket_texts_output[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Org Part</th>\n",
       "      <th>Name Part</th>\n",
       "      <th>Stripped Txt</th>\n",
       "      <th>RTW Txt</th>\n",
       "      <th>POS treat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPLAINT against Cardiogenics Holdings, Inc. ...</td>\n",
       "      <td>Cardiogenics Holdings , Inc. LG Capital Funding</td>\n",
       "      <td>( Steinmetz Michael Bowens Priscilla</td>\n",
       "      <td>COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...</td>\n",
       "      <td>COMPLAINT against filing fee $ 400 , receipt n...</td>\n",
       "      <td>[complaint file fee receipt number disclosure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case assigned to Judge Ann M Donnelly and Magi...</td>\n",
       "      <td>Individual Practices of the assigned Judges</td>\n",
       "      <td>Ann M Donnelly Vera M. Scanlon Bowens Priscilla</td>\n",
       "      <td>Case assigned to Judge -NAME- -NAME- -NAME- an...</td>\n",
       "      <td>Case assigned to Judge and Magistrate Judge . ...</td>\n",
       "      <td>[case assign judge magistrate judge ., please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summons Issued as to Cardiogenics Holdings, In...</td>\n",
       "      <td>Cardiogenics Holdings</td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...</td>\n",
       "      <td>Summons Issued as to , Inc.. ( , ) ( Entered :...</td>\n",
       "      <td>[summons issue inc.. enter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td></td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td>NOTICE - emailed attorney regarding missing se...</td>\n",
       "      <td>[notice email attorney regard miss second page...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td></td>\n",
       "      <td>Bowens Priscilla</td>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td>In accordance with Rule 73 of the Federal Rule...</td>\n",
       "      <td>[accordance rule federal rule civil procedure ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Original Text  \\\n",
       "0  COMPLAINT against Cardiogenics Holdings, Inc. ...   \n",
       "1  Case assigned to Judge Ann M Donnelly and Magi...   \n",
       "2  Summons Issued as to Cardiogenics Holdings, In...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                                          Org Part  \\\n",
       "0  Cardiogenics Holdings , Inc. LG Capital Funding   \n",
       "1      Individual Practices of the assigned Judges   \n",
       "2                            Cardiogenics Holdings   \n",
       "3                                                    \n",
       "4                                                    \n",
       "\n",
       "                                         Name Part  \\\n",
       "0             ( Steinmetz Michael Bowens Priscilla   \n",
       "1  Ann M Donnelly Vera M. Scanlon Bowens Priscilla   \n",
       "2                                 Bowens Priscilla   \n",
       "3                                 Bowens Priscilla   \n",
       "4                                 Bowens Priscilla   \n",
       "\n",
       "                                        Stripped Txt  \\\n",
       "0  COMPLAINT against -ORG- -ORG- -ORG- -ORG- fili...   \n",
       "1  Case assigned to Judge -NAME- -NAME- -NAME- an...   \n",
       "2  Summons Issued as to -ORG- -ORG- , Inc.. ( -NA...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                                             RTW Txt  \\\n",
       "0  COMPLAINT against filing fee $ 400 , receipt n...   \n",
       "1  Case assigned to Judge and Magistrate Judge . ...   \n",
       "2  Summons Issued as to , Inc.. ( , ) ( Entered :...   \n",
       "3  NOTICE - emailed attorney regarding missing se...   \n",
       "4  In accordance with Rule 73 of the Federal Rule...   \n",
       "\n",
       "                                           POS treat  \n",
       "0  [complaint file fee receipt number disclosure ...  \n",
       "1  [case assign judge magistrate judge ., please ...  \n",
       "2                        [summons issue inc.. enter]  \n",
       "3  [notice email attorney regard miss second page...  \n",
       "4  [accordance rule federal rule civil procedure ...  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['POS treat'] = pd.Series(docket_texts_output)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = 'docket_texts/unigram_nltk_noorgnoname.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# turn the lemmatized corpus into unigram sentences\n",
    "with codecs.open(unigram_sentences_filepath, 'w', encoding = 'utf_8') as f:\n",
    "    for docket_text in docket_texts_output:\n",
    "        for sentence in docket_text:\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_sentences = LineSentence(unigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:\n",
      "['complaint file fee receipt number disclosure statement civil cover sheet complete yes file llc .', 'additional attachment add civil cover sheet proposed summons .', 'enter']\n",
      "\n",
      "unigram_sentence:\n",
      "complaint file fee receipt number disclosure statement civil cover sheet complete yes file llc .\n",
      "\n",
      "additional attachment add civil cover sheet proposed summons .\n",
      "\n",
      "enter\n",
      "\n",
      "case assign judge magistrate judge .\n",
      "\n",
      "please download review locate website .\n",
      "\n",
      "attorney responsible provide courtesy copy judge individual practice require .\n",
      "\n",
      "enter\n",
      "\n",
      "summons issue inc.. enter\n",
      "\n",
      "notice email attorney regard miss second page civil cover sheet .\n",
      "\n",
      "enter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let's do some comparision between the original text and unigram sentences, shouldn't be that different.\n",
    "print('original text:')\n",
    "print(new_df['POS treat'].iloc[0])\n",
    "#print(df['Docket Text'].iloc[1])\n",
    "\n",
    "print('\\nunigram_sentence:')\n",
    "for unigram_sentence in it.islice(unigram_sentences, 0, 10):\n",
    "    print(' '.join(unigram_sentence))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model_filepath = 'docket_texts/bigram_model_noorgnoname' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 206 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# store our bigram model\n",
    "bigram_model = Phrases(unigram_sentences)\n",
    "bigram_model.save(bigram_model_filepath)\n",
    "    \n",
    "# load the finished model from disk if we don't want to run this again\n",
    "#bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sentences_filepath = 'docket_texts/bigram_sentences_noorgnoname.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 567 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# apply the bigram model, and write it to file\n",
    "with codecs.open(bigram_sentences_filepath, 'w', encoding = 'utf_8') as f:\n",
    "    for unigram_sentence in unigram_sentences:\n",
    "        bigram_sentence = ' '.join(bigram_model[unigram_sentence])\n",
    "        f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram length = 11502, bigram length = 11502\n"
     ]
    }
   ],
   "source": [
    "bigram_sentences = LineSentence(bigram_sentences_filepath)\n",
    "print('unigram length = {}, bigram length = {}'.format(len(list(unigram_sentences)), len(list(bigram_sentences))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:\n",
      "['complaint file fee receipt number disclosure statement civil cover sheet complete yes file llc .', 'additional attachment add civil cover sheet proposed summons .', 'enter']\n",
      "['case assign judge magistrate judge .', 'please download review locate website .', 'attorney responsible provide courtesy copy judge individual practice require .', 'enter']\n",
      "\n",
      "unigram sentence:\n",
      "complaint file fee receipt number disclosure statement civil cover sheet complete yes file llc .\n",
      "additional attachment add civil cover sheet proposed summons .\n",
      "enter\n",
      "case assign judge magistrate judge .\n",
      "please download review locate website .\n",
      "attorney responsible provide courtesy copy judge individual practice require .\n",
      "enter\n",
      "summons issue inc.. enter\n",
      "notice email attorney regard miss second page civil cover sheet .\n",
      "enter\n",
      "\n",
      "bigram sentence:\n",
      "complaint file fee_receipt number disclosure_statement civil_cover sheet complete_yes file llc .\n",
      "additional attachment_add civil_cover sheet proposed summons .\n",
      "enter\n",
      "case assign judge magistrate_judge .\n",
      "please_download review_locate website .\n",
      "attorney_responsible provide_courtesy copy judge individual_practice require .\n",
      "enter\n",
      "summons_issue inc.. enter\n",
      "notice email attorney regard miss second page civil_cover sheet .\n",
      "enter\n"
     ]
    }
   ],
   "source": [
    "#original v. unigram v. bigram. Some phrases should be combined already\n",
    "start = 0\n",
    "finish = 10\n",
    "print('original text:')\n",
    "print(new_df['POS treat'].iloc[0])\n",
    "print(new_df['POS treat'].iloc[1])\n",
    "\n",
    "print('\\nunigram sentence:')\n",
    "for unigram_sentence in it.islice(unigram_sentences, 0, 10):\n",
    "    print(' '.join(unigram_sentence))\n",
    "print('\\nbigram sentence:')\n",
    "for bigram_sentence in it.islice(bigram_sentences, start, finish):\n",
    "    print(' '.join(bigram_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_model_filepath = 'docket_texts/trigram_model_nonamenoorg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 213 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# again, using Phrases to attach more words to phrases already formed\n",
    "trigram_model = Phrases(bigram_sentences)\n",
    "trigram_model.save(trigram_model_filepath)\n",
    "\n",
    "# load the finished model from disk\n",
    "#trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = 'docket_texts/trigram_sentences_nonamenoorg.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 455 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with codecs.open(trigram_sentences_filepath, 'w', encoding = 'utf_8') as f:\n",
    "    for bigram_sentence in bigram_sentences:\n",
    "        #print('Bi', bigram_sentence)\n",
    "        trigram_sentence = ' '.join(trigram_model[bigram_sentence])\n",
    "        #print('Tri', trigram_sentence)\n",
    "        f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:\n",
      "['complaint file fee receipt number disclosure statement civil cover sheet complete yes file llc .', 'additional attachment add civil cover sheet proposed summons .', 'enter'] \n",
      "\n",
      "['case assign judge magistrate judge .', 'please download review locate website .', 'attorney responsible provide courtesy copy judge individual practice require .', 'enter'] \n",
      "\n",
      "['summons issue inc.. enter'] \n",
      "\n",
      "['notice email attorney regard miss second page civil cover sheet .', 'enter'] \n",
      "\n",
      "\n",
      "UNIGRAM Sentence:\n",
      "complaint file fee receipt number disclosure statement civil cover sheet complete yes file llc .\n",
      "additional attachment add civil cover sheet proposed summons .\n",
      "enter\n",
      "case assign judge magistrate judge .\n",
      "please download review locate website .\n",
      "attorney responsible provide courtesy copy judge individual practice require .\n",
      "enter\n",
      "summons issue inc.. enter\n",
      "notice email attorney regard miss second page civil cover sheet .\n",
      "enter\n",
      "accordance rule federal rule civil procedure local rule party notify party consent united state magistrate judge court available conduct proceeding civil action include jury nonjury trial order entry final judgment .\n",
      "attach notice blank copy consent form fill sign file electronically party wish consent .\n",
      "form may also access follow link http www.uscourts.govuscourtsformsandfeesformsao085.pdf .\n",
      "may withhold consent without adverse substantive consequence .\n",
      "return file consent unless party sign consent .\n",
      "\n",
      "BIGRAM Sentence:\n",
      "complaint file fee_receipt number disclosure_statement civil_cover sheet complete_yes file llc .\n",
      "additional attachment_add civil_cover sheet proposed summons .\n",
      "enter\n",
      "case assign judge magistrate_judge .\n",
      "please_download review_locate website .\n",
      "attorney_responsible provide_courtesy copy judge individual_practice require .\n",
      "enter\n",
      "summons_issue inc.. enter\n",
      "notice email attorney regard miss second page civil_cover sheet .\n",
      "enter\n",
      "accordance rule_federal rule_civil procedure_local rule party notify party consent united_state magistrate_judge court available_conduct proceeding civil action include jury_nonjury trial order entry final judgment .\n",
      "attach notice blank copy consent form_fill sign file electronically party_wish consent .\n",
      "form may also_access follow_link http_www.uscourts.govuscourtsformsandfeesformsao085.pdf .\n",
      "may_withhold consent without_adverse substantive_consequence .\n",
      "return file consent_unless party sign consent .\n",
      "\n",
      "TRIGRAM Sentence:\n",
      "complaint file fee_receipt_number disclosure_statement_civil_cover sheet_complete_yes file llc .\n",
      "additional_attachment_add civil_cover_sheet proposed summons .\n",
      "enter\n",
      "case_assign judge magistrate_judge .\n",
      "please_download_review_locate website .\n",
      "attorney_responsible_provide_courtesy copy judge_individual_practice require .\n",
      "enter\n",
      "summons_issue inc.. enter\n",
      "notice email attorney regard miss second page civil_cover_sheet .\n",
      "enter\n",
      "accordance_rule_federal rule_civil_procedure_local rule party notify party consent united_state_magistrate_judge court available_conduct_proceeding civil_action include_jury_nonjury trial order entry_final judgment .\n",
      "attach notice blank_copy consent_form_fill sign file electronically_party_wish consent .\n",
      "form may_also_access follow_link_http_www.uscourts.govuscourtsformsandfeesformsao085.pdf .\n",
      "may_withhold_consent without_adverse_substantive_consequence .\n",
      "return file consent_unless party sign consent .\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "finish = 15\n",
    "print('original text:')\n",
    "print(new_df['POS treat'].iloc[0],'\\n')\n",
    "print(new_df['POS treat'].iloc[1],'\\n')\n",
    "print(new_df['POS treat'].iloc[2],'\\n')\n",
    "print(new_df['POS treat'].iloc[3],'\\n')\n",
    "\n",
    "print('\\nUNIGRAM Sentence:')\n",
    "for unigram_sentence in it.islice(unigram_sentences, start, finish):\n",
    "    print(' '.join(unigram_sentence))\n",
    "print('\\nBIGRAM Sentence:')\n",
    "for bigram_sentence in it.islice(bigram_sentences, start, finish):\n",
    "    print(' '.join(bigram_sentence))\n",
    "print('\\nTRIGRAM Sentence:')\n",
    "for trigram_sentence in it.islice(trigram_sentences, start, finish):\n",
    "    print(' '.join(trigram_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_transform(texts):\n",
    "    trigram_output = []\n",
    "    #print(texts)\n",
    "    \n",
    "    for sentence in texts:\n",
    "        unigram_review = []\n",
    "        for word in sentence.split():\n",
    "            unigram_review.append(word)\n",
    "    \n",
    "        #print('Uni: ', unigram_review)\n",
    "        bigram_review = bigram_model[unigram_review]\n",
    "        #print('Bi: ', bigram_review)\n",
    "        trigram_review = trigram_model[bigram_review]\n",
    "        #print('Tri: ', trigram_review)\n",
    "        trigram_output.append(' '.join(trigram_review))\n",
    "    return trigram_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "new_df['Phrase Model'] = new_df['POS treat'].apply(trigram_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complaint file fee_receipt_number disclosure_statement_civil_cover sheet_complete_yes file llc .',\n",
       " 'additional_attachment_add civil_cover_sheet proposed summons .',\n",
       " 'enter']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Phrase Model'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write trigram to file\n",
    "trigram_dockets_filepath = 'docket_texts/trigram_transformed_dockets_noorgnoname.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summons_issue inc.. enter'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(trigram_dockets_filepath, 'w', encoding= 'utf_8') as f:\n",
    "    for i in range(len(new_df['Phrase Model'])):\n",
    "        f.write(' '.join(new_df['Phrase Model'][i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_dictionary_filepath = 'docket_texts/trigram_dict_noorgnoname.dict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#some dictionary hyperparameters:\n",
    "no_below = 10 #reference is 10\n",
    "no_above = 0.4 #reference is 0.4\n",
    "\n",
    "trigram_reviews = LineSentence(trigram_dockets_filepath)\n",
    "\n",
    "# learn the dictionary by iterating over all of the reviews\n",
    "trigram_dictionary = Dictionary(trigram_reviews)\n",
    "\n",
    "# filter tokens that are very rare otrigram_reviewsr too common from\n",
    "# the dictionary (filter_extremes) and reassign integer ids (compactify)\n",
    "trigram_dictionary.filter_extremes(no_below = no_below, no_above = no_above) #this step is questionable. May need to change the parameters\n",
    "trigram_dictionary.compactify()\n",
    "\n",
    "trigram_dictionary.save(trigram_dictionary_filepath)\n",
    "    \n",
    "# load the finished dictionary from disk\n",
    "#trigram_dictionary = Dictionary.load(trigram_dictionary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_bow_filepath = 'docket_texts/trigram_bow_corpus_noorgnoname.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_bow_generator(filepath):\n",
    "    \"\"\"\n",
    "    generator function to read reviews from a file\n",
    "    and yield a bag-of-words representation\n",
    "    \"\"\"\n",
    "    \n",
    "    for review in LineSentence(filepath):\n",
    "        yield trigram_dictionary.doc2bow(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 212 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# generate bag-of-words representations for\n",
    "# all reviews and save them as a matrix\n",
    "MmCorpus.serialize(trigram_bow_filepath, trigram_bow_generator(trigram_sentences_filepath))\n",
    "    \n",
    "# load the finished bag-of-words corpus from disk\n",
    "trigram_bow_corpus = MmCorpus(trigram_bow_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_topic(model, topic_number, topn = 10):\n",
    "    \"\"\"\n",
    "    accept a user-supplied topic number and\n",
    "    print out a formatted list of the top terms\n",
    "    \"\"\"\n",
    "        \n",
    "    print('{:20} {}'.format('term', 'frequency') + '\\n')\n",
    "\n",
    "    for term, frequency in model.show_topic(topic_number, topn = topn):\n",
    "        print('{:20} {:.3f}'.format(term, round(frequency, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modeling_pipeline(num_topics, model_file_path, trigram_bow_corpus, trigram_dictionary):\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        # workers => sets the parallelism, and should be\n",
    "        # set to your number of physical cores minus one\n",
    "        lda = LdaMulticore(trigram_bow_corpus, num_topics = num_topics, id2word = trigram_dictionary, workers = 4)\n",
    "\n",
    "    lda.save(model_file_path)\n",
    "    \n",
    "    for i in range(num_topics):\n",
    "        print(\"\\n Topic {}'s make-up:\".format(i + 1))\n",
    "        explore_topic(lda, topic_number = i)\n",
    "    \n",
    "    LDAvis_data_filepath = model_file_path + '_ldavis'\n",
    "    \n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda, trigram_bow_corpus, trigram_dictionary)\n",
    "\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "        \n",
    "    return LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Topic 1's make-up:\n",
      "term                 frequency\n",
      "\n",
      "exhibit              0.117\n",
      "motion               0.067\n",
      "order                0.047\n",
      "notice               0.018\n",
      "'s                   0.013\n",
      "court                0.010\n",
      "sign_judge           0.010\n",
      "attachment           0.009\n",
      "memorandum_law_support 0.008\n",
      "complaint            0.008\n",
      "\n",
      " Topic 2's make-up:\n",
      "term                 frequency\n",
      "\n",
      "motion               0.033\n",
      "order                0.033\n",
      "defendant            0.021\n",
      "'s                   0.015\n",
      "shall                0.014\n",
      "date                 0.013\n",
      "case                 0.013\n",
      "party                0.011\n",
      "plaintiff            0.011\n",
      "letter               0.010\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-327-358bf3a7e098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlda2_model_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'docket_texts/lda_model_noorgnomodel_2'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLDAvis_prepared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopic_modeling_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda2_model_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrigram_bow_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrigram_dictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLDAvis_prepared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pyLDAvis\\_display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(data, local, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'd3_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ldavis_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ldavis_css_url'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrite_ipynb_local_js\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepared_data_to_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m def show(data, ip='127.0.0.1', port=8888, n_retries=50,\n",
      "\u001b[1;32mc:\\users\\inves\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pyLDAvis\\_display.py\u001b[0m in \u001b[0;36mprepared_data_to_html\u001b[1;34m(data, d3_url, ldavis_url, ldavis_css_url, template_type, visid, use_http)\u001b[0m\n\u001b[0;32m    176\u001b[0m                            \u001b[0md3_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md3_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                            \u001b[0mldavis_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mldavis_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                            \u001b[0mvis_json\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                            ldavis_css_url=ldavis_css_url)\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "lda2_model_filepath = 'docket_texts/lda_model_noorgnomodel_2'\n",
    "LDAvis_prepared = topic_modeling_pipeline(2, lda2_model_filepath, trigram_bow_corpus, trigram_dictionary)\n",
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#note that we can change # of topics any time\n",
    "num_topics = 2\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "    # workers => sets the parallelism, and should be\n",
    "    # set to your number of physical cores minus one\n",
    "    lda2 = LdaMulticore(trigram_bow_corpus, num_topics = num_topics, id2word = trigram_dictionary, workers = 4)\n",
    "\n",
    "lda2.save(lda2_model_filepath)\n",
    "\n",
    "# load the finished LDA model from disk\n",
    "#lda = LdaMulticore.load(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Topic 1's make-up:\n",
      "term                 frequency\n",
      "\n",
      "exhibit              0.124\n",
      "motion               0.050\n",
      "order                0.024\n",
      "'s                   0.016\n",
      "notice               0.016\n",
      "defendant            0.012\n",
      "shall                0.011\n",
      "request              0.010\n",
      "letter               0.010\n",
      "judge                0.010\n",
      "\n",
      " Topic 2's make-up:\n",
      "term                 frequency\n",
      "\n",
      "order                0.062\n",
      "motion               0.055\n",
      "party                0.013\n",
      "plaintiff            0.012\n",
      "defendant            0.012\n",
      "date                 0.011\n",
      "'s                   0.011\n",
      "court                0.009\n",
      "notice               0.009\n",
      "action               0.008\n"
     ]
    }
   ],
   "source": [
    "# try looking at different topics' constitutinos\n",
    "# we might want to \n",
    "for i in range(num_topics):\n",
    "    print(\"\\n Topic {}'s make-up:\".format(i + 1))\n",
    "    explore_topic(lda2, topic_number = i)\n",
    "\n",
    "\n",
    "#seems like topic:\n",
    "#0: \n",
    "#1: \n",
    "#2: \n",
    "#3: \n",
    "#4: \n",
    "#etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvis_data_filepath = 'docket_texts/ldavis_prepared'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda2, trigram_bow_corpus, trigram_dictionary)\n",
    "\n",
    "with open(LDAvis_data_filepath, 'wb') as f:\n",
    "    pickle.dump(LDAvis_prepared, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1345219840106976085294366329\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1345219840106976085294366329_data = {\"tinfo\": {\"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5514, 0.537, 0.5324, 0.5313, 0.5137, 0.506, 0.5024, 0.5015, 0.4984, 0.4975, 0.4939, 0.4931, 0.4875, 0.4868, 0.4786, 0.477, 0.4768, 0.4736, 0.4727, 0.469, 0.4666, 0.4659, 0.4637, 0.4622, 0.4594, 0.4587, 0.4572, 0.4554, 0.4523, 0.4501, 0.4305, 0.4428, 0.396, 0.3459, 0.4263, 0.4314, 0.3358, 0.3331, 0.4066, 0.3949, 0.2694, 0.3197, 0.3475, 0.4085, 0.0348, 0.3012, 0.2474, 0.2331, 0.0366, 0.2206, 0.1975, 0.2868, 0.26, 0.0174, 0.1491, 0.0936, -0.0571, 0.099, 0.2154, 0.2116, 0.1992, -0.1642, -0.0228, -0.0827, -1.0934, -0.0741, -0.0451, -0.1823, -0.008, 0.6864, 0.67, 0.6636, 0.6428, 0.6423, 0.6232, 0.62, 0.6187, 0.6156, 0.6117, 0.6066, 0.6062, 0.6042, 0.5964, 0.5951, 0.5926, 0.591, 0.5905, 0.5873, 0.5847, 0.5827, 0.5812, 0.5801, 0.5751, 0.5742, 0.5719, 0.5704, 0.5689, 0.563, 0.5623, 0.558, 0.5599, 0.555, 0.5041, 0.4966, 0.5225, 0.5515, 0.4882, 0.4897, 0.5421, 0.5198, 0.4017, 0.418, 0.4205, 0.4236, 0.3415, 0.4087, -0.0432, 0.1663, -0.0455, 0.2529, 0.0642, 0.1816, 0.3077, -0.0212, 0.2439, 0.0906, 0.0819, 0.0266, 0.0513, -0.1247, 0.134, -0.3023, -0.1327, -0.4612, -0.3764, -0.3495, -0.4085, -0.6809], \"Total\": [2008.0, 310.0, 206.0, 313.0, 176.0, 426.0, 114.0, 109.0, 424.0, 103.0, 56.0, 350.0, 345.0, 65.0, 166.0, 109.0, 76.0, 88.0, 211.0, 95.0, 99.0, 127.0, 50.0, 58.0, 123.0, 112.0, 105.0, 56.0, 484.0, 40.0, 50.76527776029004, 17.333242563731137, 17.30651029823906, 29.126965049629977, 103.34228047169384, 17.368611396367633, 9.894354353868957, 47.71739110621118, 44.55816922064703, 47.6555793443813, 40.433184934427636, 15.99870903064149, 23.787590994362294, 14.560996337913293, 95.13540266095298, 12.90505295265595, 47.34517655169555, 49.86547887995612, 23.62290848345134, 19.30220826528155, 13.127644787264298, 47.18500496046957, 44.07596889924724, 43.43022075384349, 21.111163292862752, 13.56794577837374, 22.566873300610677, 19.013751639250664, 46.991511224335945, 58.615776182671354, 127.92952642959902, 42.07316132047877, 426.7092150904169, 424.2772412732304, 49.98840340233603, 43.107072834837204, 350.8281501000436, 345.64450895816225, 69.85874337139593, 78.73117981235822, 387.07902509709174, 200.43832373802462, 131.30557375183884, 58.97638017224118, 3058.7342022264816, 189.29275240958458, 321.67308444441954, 334.2821629397823, 1768.2497292208081, 316.55108097308795, 366.58318848880396, 170.98938636403602, 158.27135386561488, 586.6567456317098, 227.58023779071544, 294.69584415953875, 524.7355156084252, 255.31435710383272, 151.4770556222734, 141.9051768421999, 140.0789654805229, 484.3916308963148, 237.24153553818638, 255.79582263368826, 2008.2102247503187, 230.93211713587345, 214.14250163061206, 258.2429343718104, 192.79916299854432, 20.64380733438852, 56.34251125084384, 25.417172566978017, 14.93141101391684, 32.34304810681017, 40.86883377782237, 11.063799956591026, 8.503236026545128, 65.0903410857608, 12.369831230496347, 114.27151682387017, 22.73443927089918, 9.228688856505089, 206.88982326457668, 34.86439744655215, 14.625658018059298, 176.37673551083512, 10.548976260243931, 58.79458400894128, 2008.2102247503187, 12.24212565971722, 109.87017867807018, 9.280987446218813, 34.796229967499, 15.877480253588143, 10.701299007977742, 13.999661045863363, 7.901242172177725, 76.45592172966897, 9.915180746040837, 56.90500481414129, 22.980391287350788, 33.353483409857176, 310.05018394018884, 313.1617468110389, 88.84649412543386, 31.845350330078375, 109.33492924297134, 99.90388374438393, 33.155896766158584, 49.8507471450596, 166.81096664768887, 123.85694994321805, 112.8495635601636, 105.47724131968303, 211.45862559619906, 104.80608027305706, 3058.7342022264816, 484.3916308963148, 1768.2497292208081, 237.6190728096259, 524.7355156084252, 258.2429343718104, 133.57469440240732, 586.6567456317098, 167.44467445239917, 255.79582263368826, 230.93211713587345, 237.24153553818638, 214.14250163061206, 294.69584415953875, 171.90051287364037, 366.58318848880396, 255.31435710383272, 387.07902509709174, 334.2821629397823, 316.55108097308795, 321.67308444441954, 424.2772412732304], \"Freq\": [2008.0, 310.0, 206.0, 313.0, 176.0, 426.0, 114.0, 109.0, 424.0, 103.0, 56.0, 350.0, 345.0, 65.0, 166.0, 109.0, 76.0, 88.0, 211.0, 95.0, 99.0, 127.0, 50.0, 58.0, 123.0, 112.0, 105.0, 56.0, 484.0, 40.0, 47.966724735366, 16.143352513305953, 16.044649729028578, 26.97492040093019, 94.02990427235825, 15.683363251375294, 8.901771215209049, 42.89472335713869, 39.92891317091054, 42.66649446279418, 36.069361738664576, 14.260728454649321, 21.08575612446697, 12.897550038962494, 83.579853120471, 11.319174838646372, 41.52036644958285, 43.588971517494144, 20.63261078196555, 16.795909820338615, 11.395555791675879, 40.92896636330526, 38.14846928901884, 37.53588847540453, 18.193752647373966, 11.685209606508167, 19.4055455121932, 16.32141339612512, 40.21450552111118, 50.0476061344542, 107.11283908026165, 35.662076875625765, 345.1653293455854, 326.4307610452656, 41.6804914503103, 36.12488104080646, 267.20580236899195, 262.54525277590557, 57.10765929738577, 63.615412759241956, 275.8847034165767, 150.22146263595047, 101.187611052938, 48.30505934098635, 1724.05325227233, 139.26581592221413, 224.26856072299302, 229.7552262831538, 998.4888957667024, 214.8638526910075, 243.1410782108284, 123.99933821974629, 111.74449873451675, 324.9811805128177, 143.81243899874872, 176.17127963919458, 269.79681129712145, 153.44965100868902, 102.28410915812711, 95.45928023508071, 93.06825111940037, 223.76576113613004, 126.23504740969948, 128.1956478036311, 366.331130394171, 116.73498419211435, 111.438899209343, 117.16066462365458, 104.11790099988424, 18.684050093213553, 50.16796553912091, 22.48528520975803, 12.937969406058754, 28.009178040829756, 34.72488154868434, 9.370317758262866, 7.192342461400116, 54.886801503145335, 10.389980116139386, 95.49357305473791, 18.990293463829207, 7.693521981670865, 171.133691845487, 28.801729266810703, 12.052312709225223, 145.110063811214, 8.67480519245287, 48.19407479111896, 1641.8790943561478, 9.988298065127283, 89.50963059365247, 7.552713577767675, 28.176840985035856, 12.84516831608265, 8.63744611732916, 11.283366276791615, 6.3587637483938, 61.16490488503584, 7.92684689640356, 45.298731476293064, 18.328093065318654, 26.46991602778209, 233.86238573196664, 234.4310823619721, 68.25594735399429, 25.18595375776328, 81.16232564596224, 74.2746277069307, 25.97562411492818, 38.193789324484534, 113.57199572595144, 85.71460529959914, 78.28811926337661, 73.40475015999495, 135.56239836554136, 71.85692927352837, 1334.6809499541516, 260.62586976018474, 769.7608334541059, 139.41336637533124, 254.93870431130372, 141.0822697481558, 82.7875339558644, 261.67556511889217, 97.35743407623856, 127.60017483005717, 114.1971329437591, 111.0064881284869, 102.70360242126905, 118.52456452034414, 89.55298167223862, 123.44211027797554, 101.86470609514372, 111.194321680515, 104.52693665662852, 101.68722828208044, 97.40452372142653, 97.84648022796475], \"Term\": [\"motion\", \"sign_judge\", \"memorandum_law_support\", \"dismiss\", \"pennsylvania\", \"court\", \"declaration_opposition\", \"minute_entry_proceeding_hold\", \"party\", \"deposition\", \"stay\", \"judge\", \"letter\", \"service_accept\", \"declaration_support\", \"attorney\", \"reply_memorandum_law_support\", \"affidavit_service\", \"summary_judgment\", \"submit\", \"support\", \"clerk\", \"mr.\", \"motion_dismiss_thirdparty\", \"opposition\", \"mro\", \"response\", \"summary_judgment.._document\", \"defendant\", \"withdraw_attorney\", \"mr.\", \"via\", \"forward\", \"conference_proceed_hold\", \"deposition\", \"copy_mail_chamber\", \"line\", \"electronically_available_public_without\", \"reportertranscriber_deadline_release_transcript\", \"court_reportertranscriber_abovecaptioned_matter\", \"document_place_vault\", \"jv\", \"gr\", \"copy_mail\", \"submit\", \"conference_call\", \"hereby_give_official_transcript\", \"sign_judge_s.d.n.y\", \"york_ny_magistrate_judge\", \"please\", \"compel\", \"official_transcript_notice\", \"transcript_may_view_court\", \"sign\", \"amendment\", \"reach\", \"date_december\", \"party_shall_submit\", \"transcript_may_make_remotely\", \"brookfield\", \"clerk\", \"pacer\", \"court\", \"party\", \"nd\", \"witness\", \"judge\", \"letter\", \"provide\", \"amend\", \"shall\", \"action\", \"seal\", \"related\", \"exhibit\", \"may\", \"request\", \"plaintiff\", \"order\", \"attachment\", \"date\", \"judgment\", \"propose\", \"'s\", \"counsel\", \"case\", \"notice\", \"schedule\", \"modify\", \"sign_magistrate_judge\", \"serve\", \"defendant\", \"grant\", \"complaint\", \"motion\", \"inc..\", \"b\", \"stipulation\", \"conference\", \"pre\", \"stay\", \"complaint_pursuant_frcp\", \"adjourn_conference\", \"dismiss.._document\", \"withdraw_attorney\", \"deny_part\", \"responsereply\", \"service_accept\", \"grant_part\", \"declaration_opposition\", \"dismiss_pursuant_rule\", \"contempt\", \"memorandum_law_support\", \"terminate\", \"discover\", \"pennsylvania\", \"support_[_]\", \"motion_dismiss_thirdparty\", \"motion\", \"office\", \"minute_entry_proceeding_hold\", \"cayman\", \"partial_summary_judgment\", \"error_deficient_docket_entry\", \"calculation\", \"pursuant_rule_b\", \"date_dec_dkt\", \"reply_memorandum_law_support\", \"cross\", \"summary_judgment.._document\", \"magistrate_judge_discovery_hear\", \"telephone_conference_hold\", \"sign_judge\", \"dismiss\", \"affidavit_service\", \"answer_due_answer_due\", \"attorney\", \"support\", \"associate_case_rjm\", \"dismiss_second_amend\", \"declaration_support\", \"opposition\", \"mro\", \"response\", \"summary_judgment\", \"reply\", \"exhibit\", \"defendant\", \"order\", \"magistrate_judge\", \"notice\", \"stipulation\", \"llc\", \"'s\", \"l.p.\", \"complaint\", \"inc..\", \"grant\", \"b\", \"case\", \"claim\", \"date\", \"schedule\", \"shall\", \"plaintiff\", \"attachment\", \"request\", \"party\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.182600021362305, -7.271599769592285, -7.277699947357178, -6.758200168609619, -5.509500026702881, -7.30049991607666, -7.866799831390381, -6.294300079345703, -6.366000175476074, -6.299699783325195, -6.467599868774414, -7.395599842071533, -7.004499912261963, -7.496099948883057, -5.627299785614014, -7.6265997886657715, -6.326900005340576, -6.278299808502197, -7.026199817657471, -7.23199987411499, -7.619900226593018, -6.341300010681152, -6.411600112915039, -6.427800178527832, -7.1519999504089355, -7.594799995422363, -7.087500095367432, -7.2606000900268555, -6.35890007019043, -6.140100002288818, -5.379199981689453, -6.479000091552734, -4.209099769592285, -4.264900207519531, -6.3231000900268555, -6.466100215911865, -4.465099811553955, -4.482699871063232, -6.008200168609619, -5.900199890136719, -4.43310022354126, -5.040999889373779, -5.436100006103516, -6.175600051879883, -2.6006999015808105, -5.116700172424316, -4.640200138092041, -4.616099834442139, -3.1468000411987305, -4.68310022354126, -4.559500217437744, -5.232800006866455, -5.336900234222412, -4.2692999839782715, -5.08459997177124, -4.8815999031066895, -4.455399990081787, -5.019700050354004, -5.425300121307373, -5.4944000244140625, -5.519800186157227, -4.642499923706055, -5.214900016784668, -5.19950008392334, -4.149600028991699, -5.2932000160217285, -5.339600086212158, -5.2895002365112305, -5.407599925994873, -6.947400093078613, -5.959700107574463, -6.762199878692627, -7.314899921417236, -6.542500019073486, -6.327600002288818, -7.637499809265137, -7.9019999504089355, -5.869800090789795, -7.534200191497803, -5.315999984741211, -6.931099891662598, -7.834700107574463, -4.732600212097168, -6.514599800109863, -7.385799884796143, -4.897600173950195, -7.714600086212158, -5.999800205230713, -2.4714999198913574, -7.573599815368652, -5.38070011138916, -7.8531999588012695, -6.536600112915039, -7.3221001625061035, -7.718999862670898, -7.451700210571289, -8.025199890136719, -5.761499881744385, -7.804800033569336, -6.061800003051758, -6.966599941253662, -6.599100112915039, -4.420300006866455, -4.417900085449219, -5.651800155639648, -6.648799896240234, -5.478600025177002, -5.567299842834473, -6.6178998947143555, -6.232399940490723, -5.142600059509277, -5.423999786376953, -5.514699935913086, -5.579100131988525, -4.96560001373291, -5.600399971008301, -2.6786000728607178, -4.311999797821045, -3.2290000915527344, -4.937600135803223, -4.334000110626221, -4.9257001876831055, -5.458799839019775, -4.308000087738037, -5.2967000007629395, -5.026199817657471, -5.1371002197265625, -5.165500164031982, -5.243199825286865, -5.099899768829346, -5.380199909210205, -5.059299945831299, -5.251399993896484, -5.16379976272583, -5.225599765777588, -5.253200054168701, -5.296199798583984, -5.2916998863220215], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"]}, \"plot.opts\": {\"ylab\": \"PC2\", \"xlab\": \"PC1\"}, \"mdsDat\": {\"y\": [0.0, 0.0], \"Freq\": [54.43904413095733, 45.560955869042665], \"x\": [0.0361483171582222, -0.0361483171582222], \"topics\": [1, 2], \"cluster\": [1, 1]}, \"topic.order\": [2, 1], \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.5539866411150548, 0.4465984614527519, 0.7483598804989602, 0.2494532934996534, 0.1339458138374128, 0.8706477899431831, 0.2363627310983381, 0.7653650340327138, 0.8128926830835335, 0.19052172259770317, 0.8526294714458217, 0.14210491190763694, 0.2198123094092139, 0.785043962175764, 0.21112383264339057, 0.7841742355325936, 0.6791952797604837, 0.3222228769096248, 0.25609382284207216, 0.7408428446502803, 0.5183464242491709, 0.4809881234023838, 0.853012674338373, 0.15354228138090714, 0.1868931985274885, 0.8410193933736984, 0.5972259313732273, 0.40380616950803444, 0.21549431152552892, 0.8619772461021157, 0.4770201009247488, 0.5235586473564315, 0.8363979996352385, 0.1641528784330842, 0.8379263895585887, 0.15235025264701613, 0.5003991022296798, 0.5003991022296798, 0.11803043757501175, 0.8655565422167528, 0.5394214289238654, 0.4616202612906155, 0.8523792998258193, 0.15497805451378532, 0.9269760839824609, 0.06866489510981191, 0.2167155086814143, 0.8668620347256571, 0.892796049000518, 0.137353238307772, 0.9212020255888818, 0.11515025319861022, 0.6327438682633926, 0.3691005898203123, 0.8085131227524505, 0.19216833642232156, 0.9023077799403523, 0.1049195092953898, 0.2017108967780145, 0.806843587112058, 0.6628781887181976, 0.3355309350301988, 0.25312475638862286, 0.7593742691658686, 0.8419420691073692, 0.13293822143800565, 0.16627065543625558, 0.8313532771812779, 0.31772491380580525, 0.6834083051672037, 0.46243573528616094, 0.53882020941825, 0.18076971816618412, 0.8134637317478286, 0.9095986615637657, 0.08708923355397757, 0.20511897627414064, 0.8204759050965625, 0.25226580450666736, 0.7472176994248122, 0.12367418144357759, 0.8657192701050431, 0.1759445197806189, 0.8357364689579397, 0.24071855864229, 0.762275435700585, 0.8903577607943293, 0.09892864008825882, 0.9011389559058032, 0.1047835995239306, 0.1889468575671528, 0.8187697161243288, 0.5636318444227956, 0.4364550535408539, 0.9245075826539104, 0.0577817239158694, 0.8828132283330852, 0.12611617547615503, 0.5311043014207731, 0.4678775988706811, 0.16168369339342625, 0.8084184669671313, 0.8871019829050754, 0.12672885470072504, 0.5066423910675046, 0.49365156052731224, 0.761056374535114, 0.23943346614587857, 0.725191210032208, 0.27487086186704657, 0.8750706055836464, 0.12501008651194948, 0.41804852993338676, 0.5792958200505502, 0.7608973763035658, 0.24013111115283636, 0.909609629705728, 0.10106773663396978, 0.3818088465645845, 0.6213751816639317, 0.4124248059772332, 0.5849698778656675, 0.21757680004135418, 0.7832764801488751, 0.7343123190434518, 0.2641411219580762, 0.17400565881852081, 0.8265268793879739, 0.18203301606163633, 0.8191485722773634, 0.6733693071929618, 0.32348133384759936, 0.18225183573373394, 0.8176434816251124, 0.18709206273705684, 0.8164017283071571, 0.9455281664497636, 0.05909551040311022, 0.31014741125995066, 0.6911856593793185, 0.840194868036879, 0.1600371177213103, 0.5145449316251024, 0.4859591020903745, 0.16337032110207877, 0.8168516055103938, 0.8689201163451987, 0.12715904141637055, 0.3068055528367283, 0.694349409051543, 0.564399916769548, 0.4354588536197916, 0.8556523653115007, 0.14260872755191678, 0.20117121902396512, 0.8046848760958605, 0.7683655126579348, 0.23098104368244668, 0.8414962130340818, 0.15778053994389035, 0.1757601415527708, 0.8221038879081216, 0.6880414975699205, 0.3141059010645289, 0.8807282444764374, 0.15542263137819484, 0.09688135369624351, 0.9203728601143133, 0.7076454283388326, 0.2969583493921887, 0.8159322262206478, 0.18608980598014774, 0.21429090248484578, 0.7857333091111012, 0.8844374967304981, 0.14740624945508302, 0.8138851496110047, 0.18651534678585524, 0.3148672282564454, 0.6869830434686082, 0.19619147425933392, 0.7978453286546247, 0.8977029509880559, 0.11221286887350698, 0.6963591634870028, 0.30154838775999676, 0.3033829819554496, 0.6920924275858694, 0.11760228657398575, 0.8232160060179002, 0.5992612469410683, 0.3995074979607122, 0.7691981163791652, 0.22847468803341545, 0.6639112423551634, 0.33552503645906107, 0.15363262556612423, 0.8449794406136832, 0.7130326938556549, 0.2867631486158612, 0.874966770612997, 0.13815264799152585, 0.2451216091349296, 0.7547165333891254, 0.8823739586643415, 0.12032372163604657, 0.6694611297066423, 0.3241601259632163, 0.10649152596850461, 0.8874293830708717, 0.4530617663736229, 0.5459975133220584, 0.88295206253935, 0.12613600893419286, 0.359408370246052, 0.6431518204403036, 0.21087776091388566, 0.7907916034270712, 0.2602501426923914, 0.7407119445860371, 0.18959185713000673, 0.8531633570850302, 0.20987313121037438, 0.7795287730671048, 0.1720953304642114, 0.8317940972436885, 0.8512175701062539, 0.14896307476859444, 0.8621478086361248, 0.13612860136359864, 0.9230817569863775, 0.057692609811648594, 0.14681113810631718, 0.8563983056201836, 0.8351297741308571, 0.16238634496988888, 0.888967589012641, 0.12699536985894871], \"Term\": [\"'s\", \"'s\", \"action\", \"action\", \"adjourn_conference\", \"adjourn_conference\", \"affidavit_service\", \"affidavit_service\", \"amend\", \"amend\", \"amendment\", \"amendment\", \"answer_due_answer_due\", \"answer_due_answer_due\", \"associate_case_rjm\", \"associate_case_rjm\", \"attachment\", \"attachment\", \"attorney\", \"attorney\", \"b\", \"b\", \"brookfield\", \"brookfield\", \"calculation\", \"calculation\", \"case\", \"case\", \"cayman\", \"cayman\", \"claim\", \"claim\", \"clerk\", \"clerk\", \"compel\", \"compel\", \"complaint\", \"complaint\", \"complaint_pursuant_frcp\", \"complaint_pursuant_frcp\", \"conference\", \"conference\", \"conference_call\", \"conference_call\", \"conference_proceed_hold\", \"conference_proceed_hold\", \"contempt\", \"contempt\", \"copy_mail\", \"copy_mail\", \"copy_mail_chamber\", \"copy_mail_chamber\", \"counsel\", \"counsel\", \"court\", \"court\", \"court_reportertranscriber_abovecaptioned_matter\", \"court_reportertranscriber_abovecaptioned_matter\", \"cross\", \"cross\", \"date\", \"date\", \"date_dec_dkt\", \"date_dec_dkt\", \"date_december\", \"date_december\", \"declaration_opposition\", \"declaration_opposition\", \"declaration_support\", \"declaration_support\", \"defendant\", \"defendant\", \"deny_part\", \"deny_part\", \"deposition\", \"deposition\", \"discover\", \"discover\", \"dismiss\", \"dismiss\", \"dismiss.._document\", \"dismiss.._document\", \"dismiss_pursuant_rule\", \"dismiss_pursuant_rule\", \"dismiss_second_amend\", \"dismiss_second_amend\", \"document_place_vault\", \"document_place_vault\", \"electronically_available_public_without\", \"electronically_available_public_without\", \"error_deficient_docket_entry\", \"error_deficient_docket_entry\", \"exhibit\", \"exhibit\", \"forward\", \"forward\", \"gr\", \"gr\", \"grant\", \"grant\", \"grant_part\", \"grant_part\", \"hereby_give_official_transcript\", \"hereby_give_official_transcript\", \"inc..\", \"inc..\", \"judge\", \"judge\", \"judgment\", \"judgment\", \"jv\", \"jv\", \"l.p.\", \"l.p.\", \"letter\", \"letter\", \"line\", \"line\", \"llc\", \"llc\", \"magistrate_judge\", \"magistrate_judge\", \"magistrate_judge_discovery_hear\", \"magistrate_judge_discovery_hear\", \"may\", \"may\", \"memorandum_law_support\", \"memorandum_law_support\", \"minute_entry_proceeding_hold\", \"minute_entry_proceeding_hold\", \"modify\", \"modify\", \"motion\", \"motion\", \"motion_dismiss_thirdparty\", \"motion_dismiss_thirdparty\", \"mr.\", \"mr.\", \"mro\", \"mro\", \"nd\", \"nd\", \"notice\", \"notice\", \"office\", \"office\", \"official_transcript_notice\", \"official_transcript_notice\", \"opposition\", \"opposition\", \"order\", \"order\", \"pacer\", \"pacer\", \"partial_summary_judgment\", \"partial_summary_judgment\", \"party\", \"party\", \"party_shall_submit\", \"party_shall_submit\", \"pennsylvania\", \"pennsylvania\", \"plaintiff\", \"plaintiff\", \"please\", \"please\", \"pre\", \"pre\", \"propose\", \"propose\", \"provide\", \"provide\", \"pursuant_rule_b\", \"pursuant_rule_b\", \"reach\", \"reach\", \"related\", \"related\", \"reply\", \"reply\", \"reply_memorandum_law_support\", \"reply_memorandum_law_support\", \"reportertranscriber_deadline_release_transcript\", \"reportertranscriber_deadline_release_transcript\", \"request\", \"request\", \"response\", \"response\", \"responsereply\", \"responsereply\", \"schedule\", \"schedule\", \"seal\", \"seal\", \"serve\", \"serve\", \"service_accept\", \"service_accept\", \"shall\", \"shall\", \"sign\", \"sign\", \"sign_judge\", \"sign_judge\", \"sign_judge_s.d.n.y\", \"sign_judge_s.d.n.y\", \"sign_magistrate_judge\", \"sign_magistrate_judge\", \"stay\", \"stay\", \"stipulation\", \"stipulation\", \"submit\", \"submit\", \"summary_judgment\", \"summary_judgment\", \"summary_judgment.._document\", \"summary_judgment.._document\", \"support\", \"support\", \"support_[_]\", \"support_[_]\", \"telephone_conference_hold\", \"telephone_conference_hold\", \"terminate\", \"terminate\", \"transcript_may_make_remotely\", \"transcript_may_make_remotely\", \"transcript_may_view_court\", \"transcript_may_view_court\", \"via\", \"via\", \"withdraw_attorney\", \"withdraw_attorney\", \"witness\", \"witness\", \"york_ny_magistrate_judge\", \"york_ny_magistrate_judge\"]}, \"R\": 30, \"lambda.step\": 0.01};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1345219840106976085294366329\", ldavis_el1345219840106976085294366329_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1345219840106976085294366329\", ldavis_el1345219840106976085294366329_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1345219840106976085294366329\", ldavis_el1345219840106976085294366329_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
